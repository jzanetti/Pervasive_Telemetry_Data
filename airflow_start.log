/home/zhangs/miniconda3/envs/airflow/bin/airflow webserver -p 8082 >> airflow-webserver.log 2>&1 &
/home/zhangs/miniconda3/envs/airflow/bin/airflow scheduler
/home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/models/base.py:49 MovedIn20Warning: Deprecated API features detected! These feature(s) are not compatible with SQLAlchemy 2.0. To prevent incompatible upgrades prior to updating applications, ensure requirements files are pinned to "sqlalchemy<2.0". Set environment variable SQLALCHEMY_WARN_20=1 to show all deprecation warnings.  Set environment variable SQLALCHEMY_SILENCE_UBER_WARNING=1 to silence this message. (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)
  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[2023-10-27 13:36:15 +1300] [796843] [INFO] Starting gunicorn 21.2.0
[[34m2023-10-27 13:36:15,596[0m] {[34mscheduler_job.py:[0m700} INFO[0m - Starting the scheduler[0m
[[34m2023-10-27 13:36:15,597[0m] {[34mscheduler_job.py:[0m705} INFO[0m - Processing each file at most -1 times[0m
[2023-10-27 13:36:15 +1300] [796843] [INFO] Listening at: http://[::]:8083 (796843)
[2023-10-27 13:36:15 +1300] [796843] [INFO] Using worker: sync
[[34m2023-10-27 13:36:15,602[0m] {[34mexecutor_loader.py:[0m107} INFO[0m - Loaded executor: SequentialExecutor[0m
[[34m2023-10-27 13:36:15,607[0m] {[34mmanager.py:[0m163} INFO[0m - Launched DagFileProcessorManager with pid: 796887[0m
[[34m2023-10-27 13:36:15,608[0m] {[34mscheduler_job.py:[0m1380} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[2023-10-27 13:36:15 +1300] [796884] [INFO] Booting worker with pid: 796884
[[34m2023-10-27 13:36:15,618[0m] {[34msettings.py:[0m58} INFO[0m - Configured default timezone Timezone('UTC')[0m
[2023-10-27T13:36:15.641+1300] {manager.py:409} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[2023-10-27 13:36:15 +1300] [796910] [INFO] Booting worker with pid: 796910
[[34m2023-10-27 13:36:15,656[0m] {[34mscheduler_job.py:[0m1403} INFO[0m - Marked 1 SchedulerJob instances as failed[0m
[[34m2023-10-27 13:36:16,338[0m] {[34mdag.py:[0m3336} INFO[0m - Setting next_dagrun for a_call_ptd to 2023-10-27T00:00:00+00:00, run_after=2023-10-28T00:00:00+00:00[0m
[[34m2023-10-27 13:36:16,506[0m] {[34mscheduler_job.py:[0m346} INFO[0m - 1 tasks up for execution:
	<TaskInstance: a_call_ptd.test_ptd scheduled__2023-10-26T00:00:00+00:00 [scheduled]>[0m
[[34m2023-10-27 13:36:16,506[0m] {[34mscheduler_job.py:[0m411} INFO[0m - DAG a_call_ptd has 0/16 running and queued tasks[0m
[[34m2023-10-27 13:36:16,506[0m] {[34mscheduler_job.py:[0m497} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: a_call_ptd.test_ptd scheduled__2023-10-26T00:00:00+00:00 [scheduled]>[0m
[[34m2023-10-27 13:36:16,514[0m] {[34mscheduler_job.py:[0m536} INFO[0m - Sending TaskInstanceKey(dag_id='a_call_ptd', task_id='test_ptd', run_id='scheduled__2023-10-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2023-10-27 13:36:16,515[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'a_call_ptd', 'test_ptd', 'scheduled__2023-10-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/ptd_airflow.py'][0m
[[34m2023-10-27 13:36:16,525[0m] {[34msequential_executor.py:[0m61} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'a_call_ptd', 'test_ptd', 'scheduled__2023-10-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/ptd_airflow.py'][0m
/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/configuration.py:755 UserWarning: Config scheduler.max_tis_per_query (value: 512) should NOT be greater than core.parallelism (value: 32). Will now use core.parallelism as the max task instances per query instead of specified value.
/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/cli_config.py:971 DeprecationWarning: The namespace option in [kubernetes] has been moved to the namespace option in [kubernetes_executor] - the old setting has been used, but please update your config.
[[34m2023-10-27T13:36:19.091+1300[0m] {[34mdagbag.py:[0m536} INFO[0m - Filling up the DagBag from /home/zhangs/airflow/dags/ptd_airflow.py[0m
[[34m2023-10-27T13:36:19.582+1300[0m] {[34mexample_kubernetes_executor.py:[0m38} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2023-10-27T13:36:19.636+1300[0m] {[34mexample_local_kubernetes_executor.py:[0m39} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 37, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2023-10-27T13:36:19.637+1300[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2023-10-27T13:36:20.296+1300[0m] {[34mdagbag.py:[0m346} ERROR[0m - Failed to import: /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_subdag_operator.py[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: no such column: slot_pool.include_deferred

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_subdag_operator.py", line 43, in <module>
    section_1 = SubDagOperator(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/operators/subdag.py", line 90, in __init__
    self._validate_pool(session)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/operators/subdag.py", line 115, in _validate_pool
    pool = session.query(Pool).filter(Pool.slots == 1).filter(Pool.pool == self.pool).first()
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/query.py", line 2824, in first
    return self.limit(1)._iter().first()
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such column: slot_pool.include_deferred
[SQL: SELECT slot_pool.id AS slot_pool_id, slot_pool.pool AS slot_pool_pool, slot_pool.slots AS slot_pool_slots, slot_pool.description AS slot_pool_description, slot_pool.include_deferred AS slot_pool_include_deferred 
FROM slot_pool 
WHERE slot_pool.slots = ? AND slot_pool.pool = ?
 LIMIT ? OFFSET ?]
[parameters: (1, 'default_pool', 1, 0)]
(Background on this error at: https://sqlalche.me/e/14/e3q8)
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: no such column: dag_run.updated_at

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/bin/airflow", line 11, in <module>
    sys.exit(main())
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/__main__.py", line 59, in main
    args.func(args)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/cli.py", line 113, in wrapper
    return f(*args, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 411, in task_run
    ti, _ = _get_ti(task, args.map_index, exec_date_or_run_id=args.execution_date_or_run_id, pool=args.pool)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 175, in _get_ti
    dag_run, dr_created = _get_dag_run(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 111, in _get_dag_run
    dag_run = dag.get_dagrun(run_id=exec_date_or_run_id, session=session)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dag.py", line 1491, in get_dagrun
    return session.scalar(query)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such column: dag_run.updated_at
[SQL: SELECT dag_run.state, dag_run.id, dag_run.dag_id, dag_run.queued_at, dag_run.execution_date, dag_run.start_date, dag_run.end_date, dag_run.run_id, dag_run.creating_job_id, dag_run.external_trigger, dag_run.run_type, dag_run.conf, dag_run.data_interval_start, dag_run.data_interval_end, dag_run.last_scheduling_decision, dag_run.dag_hash, dag_run.log_template_id, dag_run.updated_at 
FROM dag_run 
WHERE dag_run.dag_id = ? AND dag_run.run_id = ?]
[parameters: ('a_call_ptd', 'scheduled__2023-10-26T00:00:00+00:00')]
(Background on this error at: https://sqlalche.me/e/14/e3q8)
[[34m2023-10-27 13:36:21,763[0m] {[34msequential_executor.py:[0m68} ERROR[0m - Failed to execute task Command '['airflow', 'tasks', 'run', 'a_call_ptd', 'test_ptd', 'scheduled__2023-10-26T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/ptd_airflow.py']' returned non-zero exit status 1..[0m
[[34m2023-10-27 13:36:21,765[0m] {[34mscheduler_job.py:[0m588} INFO[0m - Executor reports execution of a_call_ptd.test_ptd run_id=scheduled__2023-10-26T00:00:00+00:00 exited with status failed for try_number 1[0m
[[34m2023-10-27 13:36:21,797[0m] {[34mscheduler_job.py:[0m631} INFO[0m - TaskInstance Finished: dag_id=a_call_ptd, task_id=test_ptd, run_id=scheduled__2023-10-26T00:00:00+00:00, map_index=-1, run_start_date=None, run_end_date=None, run_duration=None, state=queued, executor_state=failed, try_number=1, max_tries=0, job_id=None, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2023-10-27 00:36:16.507915+00:00, queued_by_job_id=11, pid=None[0m
[[34m2023-10-27 13:36:21,797[0m] {[34mscheduler_job.py:[0m673} ERROR[0m - Executor reports task instance <TaskInstance: a_call_ptd.test_ptd scheduled__2023-10-26T00:00:00+00:00 [queued]> finished (failed) although the task says its queued. (Info: None) Was the task killed externally?[0m
[[34m2023-10-27 13:36:21,798[0m] {[34mtaskinstance.py:[0m1853} ERROR[0m - Executor reports task instance <TaskInstance: a_call_ptd.test_ptd scheduled__2023-10-26T00:00:00+00:00 [queued]> finished (failed) although the task says its queued. (Info: None) Was the task killed externally?[0m
[[34m2023-10-27 13:36:21,937[0m] {[34mtaskinstance.py:[0m1401} INFO[0m - Marking task as FAILED. dag_id=a_call_ptd, task_id=test_ptd, execution_date=20231026T000000, start_date=, end_date=20231027T003621[0m
[[34m2023-10-27 13:36:22,576[0m] {[34mdagrun.py:[0m578} ERROR[0m - Marking run <DagRun a_call_ptd @ 2023-10-26 00:00:00+00:00: scheduled__2023-10-26T00:00:00+00:00, state:running, queued_at: 2023-10-27 00:36:16.320189+00:00. externally triggered: False> failed[0m
[[34m2023-10-27 13:36:22,576[0m] {[34mdagrun.py:[0m644} INFO[0m - DagRun Finished: dag_id=a_call_ptd, execution_date=2023-10-26 00:00:00+00:00, run_id=scheduled__2023-10-26T00:00:00+00:00, run_start_date=2023-10-27 00:36:16.380277+00:00, run_end_date=2023-10-27 00:36:22.576743+00:00, run_duration=6.196466, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-10-26 00:00:00+00:00, data_interval_end=2023-10-27 00:00:00+00:00, dag_hash=ef39cd88a0086a41612ae0027b034d06[0m
[[34m2023-10-27 13:36:22,585[0m] {[34mdagrun.py:[0m837} WARNING[0m - Failed to record first_task_scheduling_delay metric:[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/models/dagrun.py", line 825, in _emit_true_scheduling_delay_stats_for_finished_state
    first_start_date = ordered_tis_by_start_date[0].start_date
IndexError: list index out of range
[[34m2023-10-27 13:36:22,589[0m] {[34mdag.py:[0m3336} INFO[0m - Setting next_dagrun for a_call_ptd to 2023-10-27T00:00:00+00:00, run_after=2023-10-28T00:00:00+00:00[0m
[[34m2023-10-27 13:36:46,807[0m] {[34mscheduler_job.py:[0m346} INFO[0m - 1 tasks up for execution:
	<TaskInstance: a_call_ptd.test_ptd manual__2023-10-27T00:36:45.486071+00:00 [scheduled]>[0m
[[34m2023-10-27 13:36:46,808[0m] {[34mscheduler_job.py:[0m411} INFO[0m - DAG a_call_ptd has 0/16 running and queued tasks[0m
[[34m2023-10-27 13:36:46,809[0m] {[34mscheduler_job.py:[0m497} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: a_call_ptd.test_ptd manual__2023-10-27T00:36:45.486071+00:00 [scheduled]>[0m
[[34m2023-10-27 13:36:46,828[0m] {[34mscheduler_job.py:[0m536} INFO[0m - Sending TaskInstanceKey(dag_id='a_call_ptd', task_id='test_ptd', run_id='manual__2023-10-27T00:36:45.486071+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2023-10-27 13:36:46,829[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'a_call_ptd', 'test_ptd', 'manual__2023-10-27T00:36:45.486071+00:00', '--local', '--subdir', 'DAGS_FOLDER/ptd_airflow.py'][0m
[[34m2023-10-27 13:36:46,844[0m] {[34msequential_executor.py:[0m61} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'a_call_ptd', 'test_ptd', 'manual__2023-10-27T00:36:45.486071+00:00', '--local', '--subdir', 'DAGS_FOLDER/ptd_airflow.py'][0m
/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/configuration.py:755 UserWarning: Config scheduler.max_tis_per_query (value: 512) should NOT be greater than core.parallelism (value: 32). Will now use core.parallelism as the max task instances per query instead of specified value.
/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/cli_config.py:971 DeprecationWarning: The namespace option in [kubernetes] has been moved to the namespace option in [kubernetes_executor] - the old setting has been used, but please update your config.
[[34m2023-10-27T13:36:48.349+1300[0m] {[34mdagbag.py:[0m536} INFO[0m - Filling up the DagBag from /home/zhangs/airflow/dags/ptd_airflow.py[0m
[[34m2023-10-27T13:36:48.574+1300[0m] {[34mexample_kubernetes_executor.py:[0m38} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2023-10-27T13:36:48.610+1300[0m] {[34mexample_local_kubernetes_executor.py:[0m39} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 37, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2023-10-27T13:36:48.611+1300[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2023-10-27T13:36:49.051+1300[0m] {[34mdagbag.py:[0m346} ERROR[0m - Failed to import: /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_subdag_operator.py[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: no such column: slot_pool.include_deferred

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_subdag_operator.py", line 43, in <module>
    section_1 = SubDagOperator(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/operators/subdag.py", line 90, in __init__
    self._validate_pool(session)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/operators/subdag.py", line 115, in _validate_pool
    pool = session.query(Pool).filter(Pool.slots == 1).filter(Pool.pool == self.pool).first()
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/query.py", line 2824, in first
    return self.limit(1)._iter().first()
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such column: slot_pool.include_deferred
[SQL: SELECT slot_pool.id AS slot_pool_id, slot_pool.pool AS slot_pool_pool, slot_pool.slots AS slot_pool_slots, slot_pool.description AS slot_pool_description, slot_pool.include_deferred AS slot_pool_include_deferred 
FROM slot_pool 
WHERE slot_pool.slots = ? AND slot_pool.pool = ?
 LIMIT ? OFFSET ?]
[parameters: (1, 'default_pool', 1, 0)]
(Background on this error at: https://sqlalche.me/e/14/e3q8)
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: no such column: dag_run.updated_at

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/bin/airflow", line 11, in <module>
    sys.exit(main())
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/__main__.py", line 59, in main
    args.func(args)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/cli.py", line 113, in wrapper
    return f(*args, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 411, in task_run
    ti, _ = _get_ti(task, args.map_index, exec_date_or_run_id=args.execution_date_or_run_id, pool=args.pool)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 175, in _get_ti
    dag_run, dr_created = _get_dag_run(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 111, in _get_dag_run
    dag_run = dag.get_dagrun(run_id=exec_date_or_run_id, session=session)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dag.py", line 1491, in get_dagrun
    return session.scalar(query)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such column: dag_run.updated_at
[SQL: SELECT dag_run.state, dag_run.id, dag_run.dag_id, dag_run.queued_at, dag_run.execution_date, dag_run.start_date, dag_run.end_date, dag_run.run_id, dag_run.creating_job_id, dag_run.external_trigger, dag_run.run_type, dag_run.conf, dag_run.data_interval_start, dag_run.data_interval_end, dag_run.last_scheduling_decision, dag_run.dag_hash, dag_run.log_template_id, dag_run.updated_at 
FROM dag_run 
WHERE dag_run.dag_id = ? AND dag_run.run_id = ?]
[parameters: ('a_call_ptd', 'manual__2023-10-27T00:36:45.486071+00:00')]
(Background on this error at: https://sqlalche.me/e/14/e3q8)
[[34m2023-10-27 13:36:50,015[0m] {[34msequential_executor.py:[0m68} ERROR[0m - Failed to execute task Command '['airflow', 'tasks', 'run', 'a_call_ptd', 'test_ptd', 'manual__2023-10-27T00:36:45.486071+00:00', '--local', '--subdir', 'DAGS_FOLDER/ptd_airflow.py']' returned non-zero exit status 1..[0m
[[34m2023-10-27 13:36:50,016[0m] {[34mscheduler_job.py:[0m588} INFO[0m - Executor reports execution of a_call_ptd.test_ptd run_id=manual__2023-10-27T00:36:45.486071+00:00 exited with status failed for try_number 1[0m
[[34m2023-10-27 13:36:50,039[0m] {[34mscheduler_job.py:[0m631} INFO[0m - TaskInstance Finished: dag_id=a_call_ptd, task_id=test_ptd, run_id=manual__2023-10-27T00:36:45.486071+00:00, map_index=-1, run_start_date=None, run_end_date=None, run_duration=None, state=queued, executor_state=failed, try_number=1, max_tries=0, job_id=None, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2023-10-27 00:36:46.810915+00:00, queued_by_job_id=11, pid=None[0m
[[34m2023-10-27 13:36:50,039[0m] {[34mscheduler_job.py:[0m673} ERROR[0m - Executor reports task instance <TaskInstance: a_call_ptd.test_ptd manual__2023-10-27T00:36:45.486071+00:00 [queued]> finished (failed) although the task says its queued. (Info: None) Was the task killed externally?[0m
[[34m2023-10-27 13:36:50,046[0m] {[34mtaskinstance.py:[0m1853} ERROR[0m - Executor reports task instance <TaskInstance: a_call_ptd.test_ptd manual__2023-10-27T00:36:45.486071+00:00 [queued]> finished (failed) although the task says its queued. (Info: None) Was the task killed externally?[0m
[[34m2023-10-27 13:36:50,071[0m] {[34mtaskinstance.py:[0m1401} INFO[0m - Marking task as FAILED. dag_id=a_call_ptd, task_id=test_ptd, execution_date=20231027T003645, start_date=, end_date=20231027T003650[0m
[[34m2023-10-27 13:36:50,645[0m] {[34mdagrun.py:[0m578} ERROR[0m - Marking run <DagRun a_call_ptd @ 2023-10-27 00:36:45.486071+00:00: manual__2023-10-27T00:36:45.486071+00:00, state:running, queued_at: 2023-10-27 00:36:45.542829+00:00. externally triggered: True> failed[0m
[[34m2023-10-27 13:36:50,646[0m] {[34mdagrun.py:[0m644} INFO[0m - DagRun Finished: dag_id=a_call_ptd, execution_date=2023-10-27 00:36:45.486071+00:00, run_id=manual__2023-10-27T00:36:45.486071+00:00, run_start_date=2023-10-27 00:36:46.544538+00:00, run_end_date=2023-10-27 00:36:50.646164+00:00, run_duration=4.101626, state=failed, external_trigger=True, run_type=manual, data_interval_start=2023-10-26 00:36:45.486071+00:00, data_interval_end=2023-10-27 00:36:45.486071+00:00, dag_hash=ef39cd88a0086a41612ae0027b034d06[0m
[[34m2023-10-27 13:36:50,655[0m] {[34mdag.py:[0m3336} INFO[0m - Setting next_dagrun for a_call_ptd to 2023-10-27T00:36:45.486071+00:00, run_after=2023-10-28T00:36:45.486071+00:00[0m
[[34m2023-10-27 13:39:55,548[0m] {[34mdag.py:[0m3336} INFO[0m - Setting next_dagrun for example_bash_operator to 2023-10-27T00:00:00+00:00, run_after=2023-10-28T00:00:00+00:00[0m
[[34m2023-10-27 13:39:55,732[0m] {[34mscheduler_job.py:[0m346} INFO[0m - 10 tasks up for execution:
	<TaskInstance: example_bash_operator.runme_0 scheduled__2023-10-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: example_bash_operator.runme_1 scheduled__2023-10-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: example_bash_operator.runme_2 scheduled__2023-10-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: example_bash_operator.runme_0 manual__2023-10-27T00:39:54.194185+00:00 [scheduled]>
	<TaskInstance: example_bash_operator.runme_1 manual__2023-10-27T00:39:54.194185+00:00 [scheduled]>
	<TaskInstance: example_bash_operator.runme_2 manual__2023-10-27T00:39:54.194185+00:00 [scheduled]>
	<TaskInstance: example_bash_operator.also_run_this scheduled__2023-10-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: example_bash_operator.this_will_skip scheduled__2023-10-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: example_bash_operator.also_run_this manual__2023-10-27T00:39:54.194185+00:00 [scheduled]>
	<TaskInstance: example_bash_operator.this_will_skip manual__2023-10-27T00:39:54.194185+00:00 [scheduled]>[0m
[[34m2023-10-27 13:39:55,733[0m] {[34mscheduler_job.py:[0m411} INFO[0m - DAG example_bash_operator has 0/16 running and queued tasks[0m
[[34m2023-10-27 13:39:55,733[0m] {[34mscheduler_job.py:[0m411} INFO[0m - DAG example_bash_operator has 1/16 running and queued tasks[0m
[[34m2023-10-27 13:39:55,734[0m] {[34mscheduler_job.py:[0m411} INFO[0m - DAG example_bash_operator has 2/16 running and queued tasks[0m
[[34m2023-10-27 13:39:55,734[0m] {[34mscheduler_job.py:[0m411} INFO[0m - DAG example_bash_operator has 3/16 running and queued tasks[0m
[[34m2023-10-27 13:39:55,735[0m] {[34mscheduler_job.py:[0m411} INFO[0m - DAG example_bash_operator has 4/16 running and queued tasks[0m
[[34m2023-10-27 13:39:55,736[0m] {[34mscheduler_job.py:[0m411} INFO[0m - DAG example_bash_operator has 5/16 running and queued tasks[0m
[[34m2023-10-27 13:39:55,736[0m] {[34mscheduler_job.py:[0m411} INFO[0m - DAG example_bash_operator has 6/16 running and queued tasks[0m
[[34m2023-10-27 13:39:55,737[0m] {[34mscheduler_job.py:[0m411} INFO[0m - DAG example_bash_operator has 7/16 running and queued tasks[0m
[[34m2023-10-27 13:39:55,738[0m] {[34mscheduler_job.py:[0m411} INFO[0m - DAG example_bash_operator has 8/16 running and queued tasks[0m
[[34m2023-10-27 13:39:55,738[0m] {[34mscheduler_job.py:[0m411} INFO[0m - DAG example_bash_operator has 9/16 running and queued tasks[0m
[[34m2023-10-27 13:39:55,739[0m] {[34mscheduler_job.py:[0m497} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: example_bash_operator.runme_0 scheduled__2023-10-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: example_bash_operator.runme_1 scheduled__2023-10-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: example_bash_operator.runme_2 scheduled__2023-10-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: example_bash_operator.runme_0 manual__2023-10-27T00:39:54.194185+00:00 [scheduled]>
	<TaskInstance: example_bash_operator.runme_1 manual__2023-10-27T00:39:54.194185+00:00 [scheduled]>
	<TaskInstance: example_bash_operator.runme_2 manual__2023-10-27T00:39:54.194185+00:00 [scheduled]>
	<TaskInstance: example_bash_operator.also_run_this scheduled__2023-10-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: example_bash_operator.this_will_skip scheduled__2023-10-26T00:00:00+00:00 [scheduled]>
	<TaskInstance: example_bash_operator.also_run_this manual__2023-10-27T00:39:54.194185+00:00 [scheduled]>
	<TaskInstance: example_bash_operator.this_will_skip manual__2023-10-27T00:39:54.194185+00:00 [scheduled]>[0m
[[34m2023-10-27 13:39:55,779[0m] {[34mscheduler_job.py:[0m536} INFO[0m - Sending TaskInstanceKey(dag_id='example_bash_operator', task_id='runme_0', run_id='scheduled__2023-10-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2023-10-27 13:39:55,779[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'example_bash_operator', 'runme_0', 'scheduled__2023-10-26T00:00:00+00:00', '--local', '--subdir', '/home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py'][0m
[[34m2023-10-27 13:39:55,780[0m] {[34mscheduler_job.py:[0m536} INFO[0m - Sending TaskInstanceKey(dag_id='example_bash_operator', task_id='runme_1', run_id='scheduled__2023-10-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2023-10-27 13:39:55,781[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'example_bash_operator', 'runme_1', 'scheduled__2023-10-26T00:00:00+00:00', '--local', '--subdir', '/home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py'][0m
[[34m2023-10-27 13:39:55,781[0m] {[34mscheduler_job.py:[0m536} INFO[0m - Sending TaskInstanceKey(dag_id='example_bash_operator', task_id='runme_2', run_id='scheduled__2023-10-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2023-10-27 13:39:55,782[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'example_bash_operator', 'runme_2', 'scheduled__2023-10-26T00:00:00+00:00', '--local', '--subdir', '/home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py'][0m
[[34m2023-10-27 13:39:55,783[0m] {[34mscheduler_job.py:[0m536} INFO[0m - Sending TaskInstanceKey(dag_id='example_bash_operator', task_id='runme_0', run_id='manual__2023-10-27T00:39:54.194185+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2023-10-27 13:39:55,783[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'example_bash_operator', 'runme_0', 'manual__2023-10-27T00:39:54.194185+00:00', '--local', '--subdir', '/home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py'][0m
[[34m2023-10-27 13:39:55,784[0m] {[34mscheduler_job.py:[0m536} INFO[0m - Sending TaskInstanceKey(dag_id='example_bash_operator', task_id='runme_1', run_id='manual__2023-10-27T00:39:54.194185+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2023-10-27 13:39:55,785[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'example_bash_operator', 'runme_1', 'manual__2023-10-27T00:39:54.194185+00:00', '--local', '--subdir', '/home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py'][0m
[[34m2023-10-27 13:39:55,786[0m] {[34mscheduler_job.py:[0m536} INFO[0m - Sending TaskInstanceKey(dag_id='example_bash_operator', task_id='runme_2', run_id='manual__2023-10-27T00:39:54.194185+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2023-10-27 13:39:55,786[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'example_bash_operator', 'runme_2', 'manual__2023-10-27T00:39:54.194185+00:00', '--local', '--subdir', '/home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py'][0m
[[34m2023-10-27 13:39:55,787[0m] {[34mscheduler_job.py:[0m536} INFO[0m - Sending TaskInstanceKey(dag_id='example_bash_operator', task_id='also_run_this', run_id='scheduled__2023-10-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2023-10-27 13:39:55,788[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'example_bash_operator', 'also_run_this', 'scheduled__2023-10-26T00:00:00+00:00', '--local', '--subdir', '/home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py'][0m
[[34m2023-10-27 13:39:55,789[0m] {[34mscheduler_job.py:[0m536} INFO[0m - Sending TaskInstanceKey(dag_id='example_bash_operator', task_id='this_will_skip', run_id='scheduled__2023-10-26T00:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2023-10-27 13:39:55,789[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'example_bash_operator', 'this_will_skip', 'scheduled__2023-10-26T00:00:00+00:00', '--local', '--subdir', '/home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py'][0m
[[34m2023-10-27 13:39:55,790[0m] {[34mscheduler_job.py:[0m536} INFO[0m - Sending TaskInstanceKey(dag_id='example_bash_operator', task_id='also_run_this', run_id='manual__2023-10-27T00:39:54.194185+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2023-10-27 13:39:55,791[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'example_bash_operator', 'also_run_this', 'manual__2023-10-27T00:39:54.194185+00:00', '--local', '--subdir', '/home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py'][0m
[[34m2023-10-27 13:39:55,791[0m] {[34mscheduler_job.py:[0m536} INFO[0m - Sending TaskInstanceKey(dag_id='example_bash_operator', task_id='this_will_skip', run_id='manual__2023-10-27T00:39:54.194185+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2023-10-27 13:39:55,792[0m] {[34mbase_executor.py:[0m95} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'example_bash_operator', 'this_will_skip', 'manual__2023-10-27T00:39:54.194185+00:00', '--local', '--subdir', '/home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py'][0m
[[34m2023-10-27 13:39:55,803[0m] {[34msequential_executor.py:[0m61} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'example_bash_operator', 'runme_0', 'scheduled__2023-10-26T00:00:00+00:00', '--local', '--subdir', '/home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py'][0m
/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/configuration.py:755 UserWarning: Config scheduler.max_tis_per_query (value: 512) should NOT be greater than core.parallelism (value: 32). Will now use core.parallelism as the max task instances per query instead of specified value.
/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/cli_config.py:971 DeprecationWarning: The namespace option in [kubernetes] has been moved to the namespace option in [kubernetes_executor] - the old setting has been used, but please update your config.
[[34m2023-10-27T13:39:57.818+1300[0m] {[34mdagbag.py:[0m536} INFO[0m - Filling up the DagBag from /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py[0m
[[34m2023-10-27T13:39:58.159+1300[0m] {[34mexample_kubernetes_executor.py:[0m38} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2023-10-27T13:39:58.197+1300[0m] {[34mexample_local_kubernetes_executor.py:[0m39} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 37, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2023-10-27T13:39:58.197+1300[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2023-10-27T13:39:58.224+1300[0m] {[34mdagbag.py:[0m505} ERROR[0m - Exception bagging dag: example_bash_operator[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 496, in _bag_dag
    raise AirflowDagDuplicatedIdException(
airflow.exceptions.AirflowDagDuplicatedIdException: Ignoring DAG example_bash_operator from /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py - also found in /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py
[[34m2023-10-27T13:39:58.225+1300[0m] {[34mdagbag.py:[0m443} ERROR[0m - Failed to bag_dag: /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 439, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 458, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 496, in _bag_dag
    raise AirflowDagDuplicatedIdException(
airflow.exceptions.AirflowDagDuplicatedIdException: Ignoring DAG example_bash_operator from /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py - also found in /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py
[[34m2023-10-27T13:39:58.227+1300[0m] {[34mdagbag.py:[0m505} ERROR[0m - Exception bagging dag: example_bash_operator[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 496, in _bag_dag
    raise AirflowDagDuplicatedIdException(
airflow.exceptions.AirflowDagDuplicatedIdException: Ignoring DAG example_bash_operator from /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py - also found in /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py
[[34m2023-10-27T13:39:58.227+1300[0m] {[34mdagbag.py:[0m443} ERROR[0m - Failed to bag_dag: /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 439, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 458, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 496, in _bag_dag
    raise AirflowDagDuplicatedIdException(
airflow.exceptions.AirflowDagDuplicatedIdException: Ignoring DAG example_bash_operator from /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py - also found in /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py
[[34m2023-10-27T13:39:58.669+1300[0m] {[34mdagbag.py:[0m346} ERROR[0m - Failed to import: /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_subdag_operator.py[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: no such column: slot_pool.include_deferred

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_subdag_operator.py", line 43, in <module>
    section_1 = SubDagOperator(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/operators/subdag.py", line 90, in __init__
    self._validate_pool(session)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/operators/subdag.py", line 115, in _validate_pool
    pool = session.query(Pool).filter(Pool.slots == 1).filter(Pool.pool == self.pool).first()
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/query.py", line 2824, in first
    return self.limit(1)._iter().first()
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such column: slot_pool.include_deferred
[SQL: SELECT slot_pool.id AS slot_pool_id, slot_pool.pool AS slot_pool_pool, slot_pool.slots AS slot_pool_slots, slot_pool.description AS slot_pool_description, slot_pool.include_deferred AS slot_pool_include_deferred 
FROM slot_pool 
WHERE slot_pool.slots = ? AND slot_pool.pool = ?
 LIMIT ? OFFSET ?]
[parameters: (1, 'default_pool', 1, 0)]
(Background on this error at: https://sqlalche.me/e/14/e3q8)
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: no such column: dag_run.updated_at

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/bin/airflow", line 11, in <module>
    sys.exit(main())
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/__main__.py", line 59, in main
    args.func(args)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/cli.py", line 113, in wrapper
    return f(*args, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 411, in task_run
    ti, _ = _get_ti(task, args.map_index, exec_date_or_run_id=args.execution_date_or_run_id, pool=args.pool)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 175, in _get_ti
    dag_run, dr_created = _get_dag_run(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 111, in _get_dag_run
    dag_run = dag.get_dagrun(run_id=exec_date_or_run_id, session=session)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dag.py", line 1491, in get_dagrun
    return session.scalar(query)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such column: dag_run.updated_at
[SQL: SELECT dag_run.state, dag_run.id, dag_run.dag_id, dag_run.queued_at, dag_run.execution_date, dag_run.start_date, dag_run.end_date, dag_run.run_id, dag_run.creating_job_id, dag_run.external_trigger, dag_run.run_type, dag_run.conf, dag_run.data_interval_start, dag_run.data_interval_end, dag_run.last_scheduling_decision, dag_run.dag_hash, dag_run.log_template_id, dag_run.updated_at 
FROM dag_run 
WHERE dag_run.dag_id = ? AND dag_run.run_id = ?]
[parameters: ('example_bash_operator', 'scheduled__2023-10-26T00:00:00+00:00')]
(Background on this error at: https://sqlalche.me/e/14/e3q8)
[[34m2023-10-27 13:39:59,722[0m] {[34msequential_executor.py:[0m68} ERROR[0m - Failed to execute task Command '['airflow', 'tasks', 'run', 'example_bash_operator', 'runme_0', 'scheduled__2023-10-26T00:00:00+00:00', '--local', '--subdir', '/home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py']' returned non-zero exit status 1..[0m
[[34m2023-10-27 13:39:59,723[0m] {[34msequential_executor.py:[0m61} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'example_bash_operator', 'runme_1', 'scheduled__2023-10-26T00:00:00+00:00', '--local', '--subdir', '/home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py'][0m
/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/configuration.py:755 UserWarning: Config scheduler.max_tis_per_query (value: 512) should NOT be greater than core.parallelism (value: 32). Will now use core.parallelism as the max task instances per query instead of specified value.
/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/cli_config.py:971 DeprecationWarning: The namespace option in [kubernetes] has been moved to the namespace option in [kubernetes_executor] - the old setting has been used, but please update your config.
[[34m2023-10-27T13:40:01.244+1300[0m] {[34mdagbag.py:[0m536} INFO[0m - Filling up the DagBag from /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py[0m
[[34m2023-10-27T13:40:01.464+1300[0m] {[34mexample_kubernetes_executor.py:[0m38} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2023-10-27T13:40:01.499+1300[0m] {[34mexample_local_kubernetes_executor.py:[0m39} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 37, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2023-10-27T13:40:01.499+1300[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2023-10-27T13:40:01.537+1300[0m] {[34mdagbag.py:[0m505} ERROR[0m - Exception bagging dag: example_bash_operator[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 496, in _bag_dag
    raise AirflowDagDuplicatedIdException(
airflow.exceptions.AirflowDagDuplicatedIdException: Ignoring DAG example_bash_operator from /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py - also found in /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py
[[34m2023-10-27T13:40:01.537+1300[0m] {[34mdagbag.py:[0m443} ERROR[0m - Failed to bag_dag: /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 439, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 458, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 496, in _bag_dag
    raise AirflowDagDuplicatedIdException(
airflow.exceptions.AirflowDagDuplicatedIdException: Ignoring DAG example_bash_operator from /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py - also found in /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py
[[34m2023-10-27T13:40:01.539+1300[0m] {[34mdagbag.py:[0m505} ERROR[0m - Exception bagging dag: example_bash_operator[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 496, in _bag_dag
    raise AirflowDagDuplicatedIdException(
airflow.exceptions.AirflowDagDuplicatedIdException: Ignoring DAG example_bash_operator from /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py - also found in /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py
[[34m2023-10-27T13:40:01.540+1300[0m] {[34mdagbag.py:[0m443} ERROR[0m - Failed to bag_dag: /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 439, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 458, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 496, in _bag_dag
    raise AirflowDagDuplicatedIdException(
airflow.exceptions.AirflowDagDuplicatedIdException: Ignoring DAG example_bash_operator from /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py - also found in /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py
[[34m2023-10-27T13:40:01.968+1300[0m] {[34mdagbag.py:[0m346} ERROR[0m - Failed to import: /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_subdag_operator.py[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: no such column: slot_pool.include_deferred

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_subdag_operator.py", line 43, in <module>
    section_1 = SubDagOperator(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/operators/subdag.py", line 90, in __init__
    self._validate_pool(session)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/operators/subdag.py", line 115, in _validate_pool
    pool = session.query(Pool).filter(Pool.slots == 1).filter(Pool.pool == self.pool).first()
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/query.py", line 2824, in first
    return self.limit(1)._iter().first()
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such column: slot_pool.include_deferred
[SQL: SELECT slot_pool.id AS slot_pool_id, slot_pool.pool AS slot_pool_pool, slot_pool.slots AS slot_pool_slots, slot_pool.description AS slot_pool_description, slot_pool.include_deferred AS slot_pool_include_deferred 
FROM slot_pool 
WHERE slot_pool.slots = ? AND slot_pool.pool = ?
 LIMIT ? OFFSET ?]
[parameters: (1, 'default_pool', 1, 0)]
(Background on this error at: https://sqlalche.me/e/14/e3q8)
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: no such column: dag_run.updated_at

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/bin/airflow", line 11, in <module>
    sys.exit(main())
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/__main__.py", line 59, in main
    args.func(args)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/cli.py", line 113, in wrapper
    return f(*args, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 411, in task_run
    ti, _ = _get_ti(task, args.map_index, exec_date_or_run_id=args.execution_date_or_run_id, pool=args.pool)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 175, in _get_ti
    dag_run, dr_created = _get_dag_run(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 111, in _get_dag_run
    dag_run = dag.get_dagrun(run_id=exec_date_or_run_id, session=session)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dag.py", line 1491, in get_dagrun
    return session.scalar(query)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such column: dag_run.updated_at
[SQL: SELECT dag_run.state, dag_run.id, dag_run.dag_id, dag_run.queued_at, dag_run.execution_date, dag_run.start_date, dag_run.end_date, dag_run.run_id, dag_run.creating_job_id, dag_run.external_trigger, dag_run.run_type, dag_run.conf, dag_run.data_interval_start, dag_run.data_interval_end, dag_run.last_scheduling_decision, dag_run.dag_hash, dag_run.log_template_id, dag_run.updated_at 
FROM dag_run 
WHERE dag_run.dag_id = ? AND dag_run.run_id = ?]
[parameters: ('example_bash_operator', 'scheduled__2023-10-26T00:00:00+00:00')]
(Background on this error at: https://sqlalche.me/e/14/e3q8)
[[34m2023-10-27 13:40:02,925[0m] {[34msequential_executor.py:[0m68} ERROR[0m - Failed to execute task Command '['airflow', 'tasks', 'run', 'example_bash_operator', 'runme_1', 'scheduled__2023-10-26T00:00:00+00:00', '--local', '--subdir', '/home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py']' returned non-zero exit status 1..[0m
[[34m2023-10-27 13:40:02,926[0m] {[34msequential_executor.py:[0m61} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'example_bash_operator', 'runme_2', 'scheduled__2023-10-26T00:00:00+00:00', '--local', '--subdir', '/home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py'][0m
/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/configuration.py:755 UserWarning: Config scheduler.max_tis_per_query (value: 512) should NOT be greater than core.parallelism (value: 32). Will now use core.parallelism as the max task instances per query instead of specified value.
/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/cli_config.py:971 DeprecationWarning: The namespace option in [kubernetes] has been moved to the namespace option in [kubernetes_executor] - the old setting has been used, but please update your config.
[[34m2023-10-27T13:40:04.405+1300[0m] {[34mdagbag.py:[0m536} INFO[0m - Filling up the DagBag from /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py[0m
[[34m2023-10-27T13:40:04.639+1300[0m] {[34mexample_kubernetes_executor.py:[0m38} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2023-10-27T13:40:04.675+1300[0m] {[34mexample_local_kubernetes_executor.py:[0m39} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 37, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2023-10-27T13:40:04.675+1300[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2023-10-27T13:40:04.698+1300[0m] {[34mdagbag.py:[0m505} ERROR[0m - Exception bagging dag: example_bash_operator[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 496, in _bag_dag
    raise AirflowDagDuplicatedIdException(
airflow.exceptions.AirflowDagDuplicatedIdException: Ignoring DAG example_bash_operator from /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py - also found in /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py
[[34m2023-10-27T13:40:04.699+1300[0m] {[34mdagbag.py:[0m443} ERROR[0m - Failed to bag_dag: /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 439, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 458, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 496, in _bag_dag
    raise AirflowDagDuplicatedIdException(
airflow.exceptions.AirflowDagDuplicatedIdException: Ignoring DAG example_bash_operator from /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py - also found in /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py
[[34m2023-10-27T13:40:04.700+1300[0m] {[34mdagbag.py:[0m505} ERROR[0m - Exception bagging dag: example_bash_operator[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 496, in _bag_dag
    raise AirflowDagDuplicatedIdException(
airflow.exceptions.AirflowDagDuplicatedIdException: Ignoring DAG example_bash_operator from /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py - also found in /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py
[[34m2023-10-27T13:40:04.701+1300[0m] {[34mdagbag.py:[0m443} ERROR[0m - Failed to bag_dag: /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 439, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 458, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 496, in _bag_dag
    raise AirflowDagDuplicatedIdException(
airflow.exceptions.AirflowDagDuplicatedIdException: Ignoring DAG example_bash_operator from /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py - also found in /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py
[[34m2023-10-27T13:40:05.097+1300[0m] {[34mdagbag.py:[0m346} ERROR[0m - Failed to import: /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_subdag_operator.py[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: no such column: slot_pool.include_deferred

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_subdag_operator.py", line 43, in <module>
    section_1 = SubDagOperator(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/operators/subdag.py", line 90, in __init__
    self._validate_pool(session)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/operators/subdag.py", line 115, in _validate_pool
    pool = session.query(Pool).filter(Pool.slots == 1).filter(Pool.pool == self.pool).first()
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/query.py", line 2824, in first
    return self.limit(1)._iter().first()
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such column: slot_pool.include_deferred
[SQL: SELECT slot_pool.id AS slot_pool_id, slot_pool.pool AS slot_pool_pool, slot_pool.slots AS slot_pool_slots, slot_pool.description AS slot_pool_description, slot_pool.include_deferred AS slot_pool_include_deferred 
FROM slot_pool 
WHERE slot_pool.slots = ? AND slot_pool.pool = ?
 LIMIT ? OFFSET ?]
[parameters: (1, 'default_pool', 1, 0)]
(Background on this error at: https://sqlalche.me/e/14/e3q8)
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: no such column: dag_run.updated_at

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/bin/airflow", line 11, in <module>
    sys.exit(main())
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/__main__.py", line 59, in main
    args.func(args)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/cli.py", line 113, in wrapper
    return f(*args, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 411, in task_run
    ti, _ = _get_ti(task, args.map_index, exec_date_or_run_id=args.execution_date_or_run_id, pool=args.pool)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 175, in _get_ti
    dag_run, dr_created = _get_dag_run(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 111, in _get_dag_run
    dag_run = dag.get_dagrun(run_id=exec_date_or_run_id, session=session)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dag.py", line 1491, in get_dagrun
    return session.scalar(query)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such column: dag_run.updated_at
[SQL: SELECT dag_run.state, dag_run.id, dag_run.dag_id, dag_run.queued_at, dag_run.execution_date, dag_run.start_date, dag_run.end_date, dag_run.run_id, dag_run.creating_job_id, dag_run.external_trigger, dag_run.run_type, dag_run.conf, dag_run.data_interval_start, dag_run.data_interval_end, dag_run.last_scheduling_decision, dag_run.dag_hash, dag_run.log_template_id, dag_run.updated_at 
FROM dag_run 
WHERE dag_run.dag_id = ? AND dag_run.run_id = ?]
[parameters: ('example_bash_operator', 'scheduled__2023-10-26T00:00:00+00:00')]
(Background on this error at: https://sqlalche.me/e/14/e3q8)
[[34m2023-10-27 13:40:05,961[0m] {[34msequential_executor.py:[0m68} ERROR[0m - Failed to execute task Command '['airflow', 'tasks', 'run', 'example_bash_operator', 'runme_2', 'scheduled__2023-10-26T00:00:00+00:00', '--local', '--subdir', '/home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py']' returned non-zero exit status 1..[0m
[[34m2023-10-27 13:40:05,962[0m] {[34msequential_executor.py:[0m61} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'example_bash_operator', 'runme_0', 'manual__2023-10-27T00:39:54.194185+00:00', '--local', '--subdir', '/home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py'][0m
/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/configuration.py:755 UserWarning: Config scheduler.max_tis_per_query (value: 512) should NOT be greater than core.parallelism (value: 32). Will now use core.parallelism as the max task instances per query instead of specified value.
/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/cli_config.py:971 DeprecationWarning: The namespace option in [kubernetes] has been moved to the namespace option in [kubernetes_executor] - the old setting has been used, but please update your config.
[[34m2023-10-27T13:40:07.470+1300[0m] {[34mdagbag.py:[0m536} INFO[0m - Filling up the DagBag from /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py[0m
[[34m2023-10-27T13:40:07.690+1300[0m] {[34mexample_kubernetes_executor.py:[0m38} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2023-10-27T13:40:07.727+1300[0m] {[34mexample_local_kubernetes_executor.py:[0m39} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 37, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2023-10-27T13:40:07.727+1300[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2023-10-27T13:40:07.758+1300[0m] {[34mdagbag.py:[0m505} ERROR[0m - Exception bagging dag: example_bash_operator[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 496, in _bag_dag
    raise AirflowDagDuplicatedIdException(
airflow.exceptions.AirflowDagDuplicatedIdException: Ignoring DAG example_bash_operator from /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py - also found in /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py
[[34m2023-10-27T13:40:07.758+1300[0m] {[34mdagbag.py:[0m443} ERROR[0m - Failed to bag_dag: /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 439, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 458, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 496, in _bag_dag
    raise AirflowDagDuplicatedIdException(
airflow.exceptions.AirflowDagDuplicatedIdException: Ignoring DAG example_bash_operator from /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py - also found in /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py
[[34m2023-10-27T13:40:07.760+1300[0m] {[34mdagbag.py:[0m505} ERROR[0m - Exception bagging dag: example_bash_operator[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 496, in _bag_dag
    raise AirflowDagDuplicatedIdException(
airflow.exceptions.AirflowDagDuplicatedIdException: Ignoring DAG example_bash_operator from /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py - also found in /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py
[[34m2023-10-27T13:40:07.760+1300[0m] {[34mdagbag.py:[0m443} ERROR[0m - Failed to bag_dag: /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 439, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 458, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 496, in _bag_dag
    raise AirflowDagDuplicatedIdException(
airflow.exceptions.AirflowDagDuplicatedIdException: Ignoring DAG example_bash_operator from /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py - also found in /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py
[[34m2023-10-27T13:40:08.153+1300[0m] {[34mdagbag.py:[0m346} ERROR[0m - Failed to import: /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_subdag_operator.py[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: no such column: slot_pool.include_deferred

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_subdag_operator.py", line 43, in <module>
    section_1 = SubDagOperator(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/operators/subdag.py", line 90, in __init__
    self._validate_pool(session)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/operators/subdag.py", line 115, in _validate_pool
    pool = session.query(Pool).filter(Pool.slots == 1).filter(Pool.pool == self.pool).first()
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/query.py", line 2824, in first
    return self.limit(1)._iter().first()
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such column: slot_pool.include_deferred
[SQL: SELECT slot_pool.id AS slot_pool_id, slot_pool.pool AS slot_pool_pool, slot_pool.slots AS slot_pool_slots, slot_pool.description AS slot_pool_description, slot_pool.include_deferred AS slot_pool_include_deferred 
FROM slot_pool 
WHERE slot_pool.slots = ? AND slot_pool.pool = ?
 LIMIT ? OFFSET ?]
[parameters: (1, 'default_pool', 1, 0)]
(Background on this error at: https://sqlalche.me/e/14/e3q8)
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: no such column: dag_run.updated_at

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/bin/airflow", line 11, in <module>
    sys.exit(main())
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/__main__.py", line 59, in main
    args.func(args)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/cli.py", line 113, in wrapper
    return f(*args, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 411, in task_run
    ti, _ = _get_ti(task, args.map_index, exec_date_or_run_id=args.execution_date_or_run_id, pool=args.pool)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 175, in _get_ti
    dag_run, dr_created = _get_dag_run(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 111, in _get_dag_run
    dag_run = dag.get_dagrun(run_id=exec_date_or_run_id, session=session)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dag.py", line 1491, in get_dagrun
    return session.scalar(query)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such column: dag_run.updated_at
[SQL: SELECT dag_run.state, dag_run.id, dag_run.dag_id, dag_run.queued_at, dag_run.execution_date, dag_run.start_date, dag_run.end_date, dag_run.run_id, dag_run.creating_job_id, dag_run.external_trigger, dag_run.run_type, dag_run.conf, dag_run.data_interval_start, dag_run.data_interval_end, dag_run.last_scheduling_decision, dag_run.dag_hash, dag_run.log_template_id, dag_run.updated_at 
FROM dag_run 
WHERE dag_run.dag_id = ? AND dag_run.run_id = ?]
[parameters: ('example_bash_operator', 'manual__2023-10-27T00:39:54.194185+00:00')]
(Background on this error at: https://sqlalche.me/e/14/e3q8)
[[34m2023-10-27 13:40:09,100[0m] {[34msequential_executor.py:[0m68} ERROR[0m - Failed to execute task Command '['airflow', 'tasks', 'run', 'example_bash_operator', 'runme_0', 'manual__2023-10-27T00:39:54.194185+00:00', '--local', '--subdir', '/home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py']' returned non-zero exit status 1..[0m
[[34m2023-10-27 13:40:09,101[0m] {[34msequential_executor.py:[0m61} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'example_bash_operator', 'runme_1', 'manual__2023-10-27T00:39:54.194185+00:00', '--local', '--subdir', '/home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py'][0m
/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/configuration.py:755 UserWarning: Config scheduler.max_tis_per_query (value: 512) should NOT be greater than core.parallelism (value: 32). Will now use core.parallelism as the max task instances per query instead of specified value.
/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/cli_config.py:971 DeprecationWarning: The namespace option in [kubernetes] has been moved to the namespace option in [kubernetes_executor] - the old setting has been used, but please update your config.
[[34m2023-10-27T13:40:10.626+1300[0m] {[34mdagbag.py:[0m536} INFO[0m - Filling up the DagBag from /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py[0m
[[34m2023-10-27T13:40:10.850+1300[0m] {[34mexample_kubernetes_executor.py:[0m38} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2023-10-27T13:40:10.887+1300[0m] {[34mexample_local_kubernetes_executor.py:[0m39} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 37, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2023-10-27T13:40:10.888+1300[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2023-10-27T13:40:10.912+1300[0m] {[34mdagbag.py:[0m505} ERROR[0m - Exception bagging dag: example_bash_operator[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 496, in _bag_dag
    raise AirflowDagDuplicatedIdException(
airflow.exceptions.AirflowDagDuplicatedIdException: Ignoring DAG example_bash_operator from /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py - also found in /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py
[[34m2023-10-27T13:40:10.913+1300[0m] {[34mdagbag.py:[0m443} ERROR[0m - Failed to bag_dag: /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 439, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 458, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 496, in _bag_dag
    raise AirflowDagDuplicatedIdException(
airflow.exceptions.AirflowDagDuplicatedIdException: Ignoring DAG example_bash_operator from /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py - also found in /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py
[[34m2023-10-27T13:40:10.914+1300[0m] {[34mdagbag.py:[0m505} ERROR[0m - Exception bagging dag: example_bash_operator[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 496, in _bag_dag
    raise AirflowDagDuplicatedIdException(
airflow.exceptions.AirflowDagDuplicatedIdException: Ignoring DAG example_bash_operator from /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py - also found in /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py
[[34m2023-10-27T13:40:10.915+1300[0m] {[34mdagbag.py:[0m443} ERROR[0m - Failed to bag_dag: /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 439, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 458, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 496, in _bag_dag
    raise AirflowDagDuplicatedIdException(
airflow.exceptions.AirflowDagDuplicatedIdException: Ignoring DAG example_bash_operator from /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py - also found in /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py
[[34m2023-10-27T13:40:11.321+1300[0m] {[34mdagbag.py:[0m346} ERROR[0m - Failed to import: /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_subdag_operator.py[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: no such column: slot_pool.include_deferred

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_subdag_operator.py", line 43, in <module>
    section_1 = SubDagOperator(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/operators/subdag.py", line 90, in __init__
    self._validate_pool(session)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/operators/subdag.py", line 115, in _validate_pool
    pool = session.query(Pool).filter(Pool.slots == 1).filter(Pool.pool == self.pool).first()
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/query.py", line 2824, in first
    return self.limit(1)._iter().first()
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such column: slot_pool.include_deferred
[SQL: SELECT slot_pool.id AS slot_pool_id, slot_pool.pool AS slot_pool_pool, slot_pool.slots AS slot_pool_slots, slot_pool.description AS slot_pool_description, slot_pool.include_deferred AS slot_pool_include_deferred 
FROM slot_pool 
WHERE slot_pool.slots = ? AND slot_pool.pool = ?
 LIMIT ? OFFSET ?]
[parameters: (1, 'default_pool', 1, 0)]
(Background on this error at: https://sqlalche.me/e/14/e3q8)
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: no such column: dag_run.updated_at

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/bin/airflow", line 11, in <module>
    sys.exit(main())
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/__main__.py", line 59, in main
    args.func(args)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/cli.py", line 113, in wrapper
    return f(*args, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 411, in task_run
    ti, _ = _get_ti(task, args.map_index, exec_date_or_run_id=args.execution_date_or_run_id, pool=args.pool)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 175, in _get_ti
    dag_run, dr_created = _get_dag_run(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 111, in _get_dag_run
    dag_run = dag.get_dagrun(run_id=exec_date_or_run_id, session=session)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dag.py", line 1491, in get_dagrun
    return session.scalar(query)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such column: dag_run.updated_at
[SQL: SELECT dag_run.state, dag_run.id, dag_run.dag_id, dag_run.queued_at, dag_run.execution_date, dag_run.start_date, dag_run.end_date, dag_run.run_id, dag_run.creating_job_id, dag_run.external_trigger, dag_run.run_type, dag_run.conf, dag_run.data_interval_start, dag_run.data_interval_end, dag_run.last_scheduling_decision, dag_run.dag_hash, dag_run.log_template_id, dag_run.updated_at 
FROM dag_run 
WHERE dag_run.dag_id = ? AND dag_run.run_id = ?]
[parameters: ('example_bash_operator', 'manual__2023-10-27T00:39:54.194185+00:00')]
(Background on this error at: https://sqlalche.me/e/14/e3q8)
[[34m2023-10-27 13:40:12,303[0m] {[34msequential_executor.py:[0m68} ERROR[0m - Failed to execute task Command '['airflow', 'tasks', 'run', 'example_bash_operator', 'runme_1', 'manual__2023-10-27T00:39:54.194185+00:00', '--local', '--subdir', '/home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py']' returned non-zero exit status 1..[0m
[[34m2023-10-27 13:40:12,304[0m] {[34msequential_executor.py:[0m61} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'example_bash_operator', 'runme_2', 'manual__2023-10-27T00:39:54.194185+00:00', '--local', '--subdir', '/home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py'][0m
/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/configuration.py:755 UserWarning: Config scheduler.max_tis_per_query (value: 512) should NOT be greater than core.parallelism (value: 32). Will now use core.parallelism as the max task instances per query instead of specified value.
/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/cli_config.py:971 DeprecationWarning: The namespace option in [kubernetes] has been moved to the namespace option in [kubernetes_executor] - the old setting has been used, but please update your config.
[[34m2023-10-27T13:40:13.806+1300[0m] {[34mdagbag.py:[0m536} INFO[0m - Filling up the DagBag from /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py[0m
[[34m2023-10-27T13:40:14.071+1300[0m] {[34mexample_kubernetes_executor.py:[0m38} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2023-10-27T13:40:14.105+1300[0m] {[34mexample_local_kubernetes_executor.py:[0m39} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 37, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2023-10-27T13:40:14.106+1300[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2023-10-27T13:40:14.130+1300[0m] {[34mdagbag.py:[0m505} ERROR[0m - Exception bagging dag: example_bash_operator[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 496, in _bag_dag
    raise AirflowDagDuplicatedIdException(
airflow.exceptions.AirflowDagDuplicatedIdException: Ignoring DAG example_bash_operator from /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py - also found in /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py
[[34m2023-10-27T13:40:14.130+1300[0m] {[34mdagbag.py:[0m443} ERROR[0m - Failed to bag_dag: /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 439, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 458, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 496, in _bag_dag
    raise AirflowDagDuplicatedIdException(
airflow.exceptions.AirflowDagDuplicatedIdException: Ignoring DAG example_bash_operator from /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py - also found in /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py
[[34m2023-10-27T13:40:14.132+1300[0m] {[34mdagbag.py:[0m505} ERROR[0m - Exception bagging dag: example_bash_operator[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 496, in _bag_dag
    raise AirflowDagDuplicatedIdException(
airflow.exceptions.AirflowDagDuplicatedIdException: Ignoring DAG example_bash_operator from /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py - also found in /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py
[[34m2023-10-27T13:40:14.133+1300[0m] {[34mdagbag.py:[0m443} ERROR[0m - Failed to bag_dag: /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 439, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 458, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 496, in _bag_dag
    raise AirflowDagDuplicatedIdException(
airflow.exceptions.AirflowDagDuplicatedIdException: Ignoring DAG example_bash_operator from /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py - also found in /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py
[[34m2023-10-27T13:40:14.509+1300[0m] {[34mdagbag.py:[0m346} ERROR[0m - Failed to import: /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_subdag_operator.py[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: no such column: slot_pool.include_deferred

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_subdag_operator.py", line 43, in <module>
    section_1 = SubDagOperator(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/operators/subdag.py", line 90, in __init__
    self._validate_pool(session)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/operators/subdag.py", line 115, in _validate_pool
    pool = session.query(Pool).filter(Pool.slots == 1).filter(Pool.pool == self.pool).first()
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/query.py", line 2824, in first
    return self.limit(1)._iter().first()
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such column: slot_pool.include_deferred
[SQL: SELECT slot_pool.id AS slot_pool_id, slot_pool.pool AS slot_pool_pool, slot_pool.slots AS slot_pool_slots, slot_pool.description AS slot_pool_description, slot_pool.include_deferred AS slot_pool_include_deferred 
FROM slot_pool 
WHERE slot_pool.slots = ? AND slot_pool.pool = ?
 LIMIT ? OFFSET ?]
[parameters: (1, 'default_pool', 1, 0)]
(Background on this error at: https://sqlalche.me/e/14/e3q8)
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: no such column: dag_run.updated_at

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/bin/airflow", line 11, in <module>
    sys.exit(main())
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/__main__.py", line 59, in main
    args.func(args)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/cli.py", line 113, in wrapper
    return f(*args, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 411, in task_run
    ti, _ = _get_ti(task, args.map_index, exec_date_or_run_id=args.execution_date_or_run_id, pool=args.pool)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 175, in _get_ti
    dag_run, dr_created = _get_dag_run(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 111, in _get_dag_run
    dag_run = dag.get_dagrun(run_id=exec_date_or_run_id, session=session)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dag.py", line 1491, in get_dagrun
    return session.scalar(query)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such column: dag_run.updated_at
[SQL: SELECT dag_run.state, dag_run.id, dag_run.dag_id, dag_run.queued_at, dag_run.execution_date, dag_run.start_date, dag_run.end_date, dag_run.run_id, dag_run.creating_job_id, dag_run.external_trigger, dag_run.run_type, dag_run.conf, dag_run.data_interval_start, dag_run.data_interval_end, dag_run.last_scheduling_decision, dag_run.dag_hash, dag_run.log_template_id, dag_run.updated_at 
FROM dag_run 
WHERE dag_run.dag_id = ? AND dag_run.run_id = ?]
[parameters: ('example_bash_operator', 'manual__2023-10-27T00:39:54.194185+00:00')]
(Background on this error at: https://sqlalche.me/e/14/e3q8)
[[34m2023-10-27 13:40:15,424[0m] {[34msequential_executor.py:[0m68} ERROR[0m - Failed to execute task Command '['airflow', 'tasks', 'run', 'example_bash_operator', 'runme_2', 'manual__2023-10-27T00:39:54.194185+00:00', '--local', '--subdir', '/home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py']' returned non-zero exit status 1..[0m
[[34m2023-10-27 13:40:15,425[0m] {[34msequential_executor.py:[0m61} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'example_bash_operator', 'also_run_this', 'scheduled__2023-10-26T00:00:00+00:00', '--local', '--subdir', '/home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py'][0m
/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/configuration.py:755 UserWarning: Config scheduler.max_tis_per_query (value: 512) should NOT be greater than core.parallelism (value: 32). Will now use core.parallelism as the max task instances per query instead of specified value.
/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/cli_config.py:971 DeprecationWarning: The namespace option in [kubernetes] has been moved to the namespace option in [kubernetes_executor] - the old setting has been used, but please update your config.
[[34m2023-10-27T13:40:16.940+1300[0m] {[34mdagbag.py:[0m536} INFO[0m - Filling up the DagBag from /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py[0m
[[34m2023-10-27T13:40:17.182+1300[0m] {[34mexample_kubernetes_executor.py:[0m38} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2023-10-27T13:40:17.232+1300[0m] {[34mexample_local_kubernetes_executor.py:[0m39} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 37, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2023-10-27T13:40:17.233+1300[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2023-10-27T13:40:17.257+1300[0m] {[34mdagbag.py:[0m505} ERROR[0m - Exception bagging dag: example_bash_operator[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 496, in _bag_dag
    raise AirflowDagDuplicatedIdException(
airflow.exceptions.AirflowDagDuplicatedIdException: Ignoring DAG example_bash_operator from /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py - also found in /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py
[[34m2023-10-27T13:40:17.257+1300[0m] {[34mdagbag.py:[0m443} ERROR[0m - Failed to bag_dag: /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 439, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 458, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 496, in _bag_dag
    raise AirflowDagDuplicatedIdException(
airflow.exceptions.AirflowDagDuplicatedIdException: Ignoring DAG example_bash_operator from /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py - also found in /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py
[[34m2023-10-27T13:40:17.259+1300[0m] {[34mdagbag.py:[0m505} ERROR[0m - Exception bagging dag: example_bash_operator[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 496, in _bag_dag
    raise AirflowDagDuplicatedIdException(
airflow.exceptions.AirflowDagDuplicatedIdException: Ignoring DAG example_bash_operator from /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py - also found in /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py
[[34m2023-10-27T13:40:17.259+1300[0m] {[34mdagbag.py:[0m443} ERROR[0m - Failed to bag_dag: /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 439, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 458, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 496, in _bag_dag
    raise AirflowDagDuplicatedIdException(
airflow.exceptions.AirflowDagDuplicatedIdException: Ignoring DAG example_bash_operator from /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py - also found in /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py
[[34m2023-10-27T13:40:17.666+1300[0m] {[34mdagbag.py:[0m346} ERROR[0m - Failed to import: /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_subdag_operator.py[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: no such column: slot_pool.include_deferred

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_subdag_operator.py", line 43, in <module>
    section_1 = SubDagOperator(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/operators/subdag.py", line 90, in __init__
    self._validate_pool(session)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/operators/subdag.py", line 115, in _validate_pool
    pool = session.query(Pool).filter(Pool.slots == 1).filter(Pool.pool == self.pool).first()
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/query.py", line 2824, in first
    return self.limit(1)._iter().first()
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such column: slot_pool.include_deferred
[SQL: SELECT slot_pool.id AS slot_pool_id, slot_pool.pool AS slot_pool_pool, slot_pool.slots AS slot_pool_slots, slot_pool.description AS slot_pool_description, slot_pool.include_deferred AS slot_pool_include_deferred 
FROM slot_pool 
WHERE slot_pool.slots = ? AND slot_pool.pool = ?
 LIMIT ? OFFSET ?]
[parameters: (1, 'default_pool', 1, 0)]
(Background on this error at: https://sqlalche.me/e/14/e3q8)
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: no such column: dag_run.updated_at

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/bin/airflow", line 11, in <module>
    sys.exit(main())
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/__main__.py", line 59, in main
    args.func(args)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/cli.py", line 113, in wrapper
    return f(*args, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 411, in task_run
    ti, _ = _get_ti(task, args.map_index, exec_date_or_run_id=args.execution_date_or_run_id, pool=args.pool)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 175, in _get_ti
    dag_run, dr_created = _get_dag_run(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 111, in _get_dag_run
    dag_run = dag.get_dagrun(run_id=exec_date_or_run_id, session=session)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dag.py", line 1491, in get_dagrun
    return session.scalar(query)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such column: dag_run.updated_at
[SQL: SELECT dag_run.state, dag_run.id, dag_run.dag_id, dag_run.queued_at, dag_run.execution_date, dag_run.start_date, dag_run.end_date, dag_run.run_id, dag_run.creating_job_id, dag_run.external_trigger, dag_run.run_type, dag_run.conf, dag_run.data_interval_start, dag_run.data_interval_end, dag_run.last_scheduling_decision, dag_run.dag_hash, dag_run.log_template_id, dag_run.updated_at 
FROM dag_run 
WHERE dag_run.dag_id = ? AND dag_run.run_id = ?]
[parameters: ('example_bash_operator', 'scheduled__2023-10-26T00:00:00+00:00')]
(Background on this error at: https://sqlalche.me/e/14/e3q8)
[[34m2023-10-27 13:40:18,611[0m] {[34msequential_executor.py:[0m68} ERROR[0m - Failed to execute task Command '['airflow', 'tasks', 'run', 'example_bash_operator', 'also_run_this', 'scheduled__2023-10-26T00:00:00+00:00', '--local', '--subdir', '/home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py']' returned non-zero exit status 1..[0m
[[34m2023-10-27 13:40:18,613[0m] {[34msequential_executor.py:[0m61} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'example_bash_operator', 'this_will_skip', 'scheduled__2023-10-26T00:00:00+00:00', '--local', '--subdir', '/home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py'][0m
/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/configuration.py:755 UserWarning: Config scheduler.max_tis_per_query (value: 512) should NOT be greater than core.parallelism (value: 32). Will now use core.parallelism as the max task instances per query instead of specified value.
/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/cli_config.py:971 DeprecationWarning: The namespace option in [kubernetes] has been moved to the namespace option in [kubernetes_executor] - the old setting has been used, but please update your config.
[[34m2023-10-27T13:40:20.115+1300[0m] {[34mdagbag.py:[0m536} INFO[0m - Filling up the DagBag from /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py[0m
[[34m2023-10-27T13:40:20.344+1300[0m] {[34mexample_kubernetes_executor.py:[0m38} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2023-10-27T13:40:20.381+1300[0m] {[34mexample_local_kubernetes_executor.py:[0m39} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 37, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2023-10-27T13:40:20.382+1300[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2023-10-27T13:40:20.406+1300[0m] {[34mdagbag.py:[0m505} ERROR[0m - Exception bagging dag: example_bash_operator[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 496, in _bag_dag
    raise AirflowDagDuplicatedIdException(
airflow.exceptions.AirflowDagDuplicatedIdException: Ignoring DAG example_bash_operator from /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py - also found in /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py
[[34m2023-10-27T13:40:20.407+1300[0m] {[34mdagbag.py:[0m443} ERROR[0m - Failed to bag_dag: /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 439, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 458, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 496, in _bag_dag
    raise AirflowDagDuplicatedIdException(
airflow.exceptions.AirflowDagDuplicatedIdException: Ignoring DAG example_bash_operator from /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py - also found in /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py
[[34m2023-10-27T13:40:20.408+1300[0m] {[34mdagbag.py:[0m505} ERROR[0m - Exception bagging dag: example_bash_operator[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 496, in _bag_dag
    raise AirflowDagDuplicatedIdException(
airflow.exceptions.AirflowDagDuplicatedIdException: Ignoring DAG example_bash_operator from /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py - also found in /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py
[[34m2023-10-27T13:40:20.408+1300[0m] {[34mdagbag.py:[0m443} ERROR[0m - Failed to bag_dag: /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 439, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 458, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 496, in _bag_dag
    raise AirflowDagDuplicatedIdException(
airflow.exceptions.AirflowDagDuplicatedIdException: Ignoring DAG example_bash_operator from /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py - also found in /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py
[[34m2023-10-27T13:40:20.817+1300[0m] {[34mdagbag.py:[0m346} ERROR[0m - Failed to import: /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_subdag_operator.py[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: no such column: slot_pool.include_deferred

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_subdag_operator.py", line 43, in <module>
    section_1 = SubDagOperator(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/operators/subdag.py", line 90, in __init__
    self._validate_pool(session)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/operators/subdag.py", line 115, in _validate_pool
    pool = session.query(Pool).filter(Pool.slots == 1).filter(Pool.pool == self.pool).first()
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/query.py", line 2824, in first
    return self.limit(1)._iter().first()
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such column: slot_pool.include_deferred
[SQL: SELECT slot_pool.id AS slot_pool_id, slot_pool.pool AS slot_pool_pool, slot_pool.slots AS slot_pool_slots, slot_pool.description AS slot_pool_description, slot_pool.include_deferred AS slot_pool_include_deferred 
FROM slot_pool 
WHERE slot_pool.slots = ? AND slot_pool.pool = ?
 LIMIT ? OFFSET ?]
[parameters: (1, 'default_pool', 1, 0)]
(Background on this error at: https://sqlalche.me/e/14/e3q8)
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: no such column: dag_run.updated_at

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/bin/airflow", line 11, in <module>
    sys.exit(main())
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/__main__.py", line 59, in main
    args.func(args)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/cli.py", line 113, in wrapper
    return f(*args, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 411, in task_run
    ti, _ = _get_ti(task, args.map_index, exec_date_or_run_id=args.execution_date_or_run_id, pool=args.pool)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 175, in _get_ti
    dag_run, dr_created = _get_dag_run(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 111, in _get_dag_run
    dag_run = dag.get_dagrun(run_id=exec_date_or_run_id, session=session)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dag.py", line 1491, in get_dagrun
    return session.scalar(query)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such column: dag_run.updated_at
[SQL: SELECT dag_run.state, dag_run.id, dag_run.dag_id, dag_run.queued_at, dag_run.execution_date, dag_run.start_date, dag_run.end_date, dag_run.run_id, dag_run.creating_job_id, dag_run.external_trigger, dag_run.run_type, dag_run.conf, dag_run.data_interval_start, dag_run.data_interval_end, dag_run.last_scheduling_decision, dag_run.dag_hash, dag_run.log_template_id, dag_run.updated_at 
FROM dag_run 
WHERE dag_run.dag_id = ? AND dag_run.run_id = ?]
[parameters: ('example_bash_operator', 'scheduled__2023-10-26T00:00:00+00:00')]
(Background on this error at: https://sqlalche.me/e/14/e3q8)
[[34m2023-10-27 13:40:21,763[0m] {[34msequential_executor.py:[0m68} ERROR[0m - Failed to execute task Command '['airflow', 'tasks', 'run', 'example_bash_operator', 'this_will_skip', 'scheduled__2023-10-26T00:00:00+00:00', '--local', '--subdir', '/home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py']' returned non-zero exit status 1..[0m
[[34m2023-10-27 13:40:21,764[0m] {[34msequential_executor.py:[0m61} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'example_bash_operator', 'also_run_this', 'manual__2023-10-27T00:39:54.194185+00:00', '--local', '--subdir', '/home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py'][0m
/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/configuration.py:755 UserWarning: Config scheduler.max_tis_per_query (value: 512) should NOT be greater than core.parallelism (value: 32). Will now use core.parallelism as the max task instances per query instead of specified value.
/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/cli_config.py:971 DeprecationWarning: The namespace option in [kubernetes] has been moved to the namespace option in [kubernetes_executor] - the old setting has been used, but please update your config.
[[34m2023-10-27T13:40:23.274+1300[0m] {[34mdagbag.py:[0m536} INFO[0m - Filling up the DagBag from /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py[0m
[[34m2023-10-27T13:40:23.523+1300[0m] {[34mexample_kubernetes_executor.py:[0m38} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2023-10-27T13:40:23.558+1300[0m] {[34mexample_local_kubernetes_executor.py:[0m39} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 37, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2023-10-27T13:40:23.559+1300[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2023-10-27T13:40:23.585+1300[0m] {[34mdagbag.py:[0m505} ERROR[0m - Exception bagging dag: example_bash_operator[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 496, in _bag_dag
    raise AirflowDagDuplicatedIdException(
airflow.exceptions.AirflowDagDuplicatedIdException: Ignoring DAG example_bash_operator from /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py - also found in /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py
[[34m2023-10-27T13:40:23.585+1300[0m] {[34mdagbag.py:[0m443} ERROR[0m - Failed to bag_dag: /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 439, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 458, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 496, in _bag_dag
    raise AirflowDagDuplicatedIdException(
airflow.exceptions.AirflowDagDuplicatedIdException: Ignoring DAG example_bash_operator from /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py - also found in /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py
[[34m2023-10-27T13:40:23.587+1300[0m] {[34mdagbag.py:[0m505} ERROR[0m - Exception bagging dag: example_bash_operator[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 496, in _bag_dag
    raise AirflowDagDuplicatedIdException(
airflow.exceptions.AirflowDagDuplicatedIdException: Ignoring DAG example_bash_operator from /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py - also found in /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py
[[34m2023-10-27T13:40:23.587+1300[0m] {[34mdagbag.py:[0m443} ERROR[0m - Failed to bag_dag: /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 439, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 458, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 496, in _bag_dag
    raise AirflowDagDuplicatedIdException(
airflow.exceptions.AirflowDagDuplicatedIdException: Ignoring DAG example_bash_operator from /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py - also found in /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py
[[34m2023-10-27T13:40:23.990+1300[0m] {[34mdagbag.py:[0m346} ERROR[0m - Failed to import: /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_subdag_operator.py[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: no such column: slot_pool.include_deferred

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_subdag_operator.py", line 43, in <module>
    section_1 = SubDagOperator(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/operators/subdag.py", line 90, in __init__
    self._validate_pool(session)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/operators/subdag.py", line 115, in _validate_pool
    pool = session.query(Pool).filter(Pool.slots == 1).filter(Pool.pool == self.pool).first()
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/query.py", line 2824, in first
    return self.limit(1)._iter().first()
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such column: slot_pool.include_deferred
[SQL: SELECT slot_pool.id AS slot_pool_id, slot_pool.pool AS slot_pool_pool, slot_pool.slots AS slot_pool_slots, slot_pool.description AS slot_pool_description, slot_pool.include_deferred AS slot_pool_include_deferred 
FROM slot_pool 
WHERE slot_pool.slots = ? AND slot_pool.pool = ?
 LIMIT ? OFFSET ?]
[parameters: (1, 'default_pool', 1, 0)]
(Background on this error at: https://sqlalche.me/e/14/e3q8)
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: no such column: dag_run.updated_at

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/bin/airflow", line 11, in <module>
    sys.exit(main())
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/__main__.py", line 59, in main
    args.func(args)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/cli.py", line 113, in wrapper
    return f(*args, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 411, in task_run
    ti, _ = _get_ti(task, args.map_index, exec_date_or_run_id=args.execution_date_or_run_id, pool=args.pool)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 175, in _get_ti
    dag_run, dr_created = _get_dag_run(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 111, in _get_dag_run
    dag_run = dag.get_dagrun(run_id=exec_date_or_run_id, session=session)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dag.py", line 1491, in get_dagrun
    return session.scalar(query)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such column: dag_run.updated_at
[SQL: SELECT dag_run.state, dag_run.id, dag_run.dag_id, dag_run.queued_at, dag_run.execution_date, dag_run.start_date, dag_run.end_date, dag_run.run_id, dag_run.creating_job_id, dag_run.external_trigger, dag_run.run_type, dag_run.conf, dag_run.data_interval_start, dag_run.data_interval_end, dag_run.last_scheduling_decision, dag_run.dag_hash, dag_run.log_template_id, dag_run.updated_at 
FROM dag_run 
WHERE dag_run.dag_id = ? AND dag_run.run_id = ?]
[parameters: ('example_bash_operator', 'manual__2023-10-27T00:39:54.194185+00:00')]
(Background on this error at: https://sqlalche.me/e/14/e3q8)
[[34m2023-10-27 13:40:24,985[0m] {[34msequential_executor.py:[0m68} ERROR[0m - Failed to execute task Command '['airflow', 'tasks', 'run', 'example_bash_operator', 'also_run_this', 'manual__2023-10-27T00:39:54.194185+00:00', '--local', '--subdir', '/home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py']' returned non-zero exit status 1..[0m
[[34m2023-10-27 13:40:24,986[0m] {[34msequential_executor.py:[0m61} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'example_bash_operator', 'this_will_skip', 'manual__2023-10-27T00:39:54.194185+00:00', '--local', '--subdir', '/home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py'][0m
/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/configuration.py:755 UserWarning: Config scheduler.max_tis_per_query (value: 512) should NOT be greater than core.parallelism (value: 32). Will now use core.parallelism as the max task instances per query instead of specified value.
/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/cli_config.py:971 DeprecationWarning: The namespace option in [kubernetes] has been moved to the namespace option in [kubernetes_executor] - the old setting has been used, but please update your config.
[[34m2023-10-27T13:40:26.547+1300[0m] {[34mdagbag.py:[0m536} INFO[0m - Filling up the DagBag from /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py[0m
[[34m2023-10-27T13:40:26.795+1300[0m] {[34mexample_kubernetes_executor.py:[0m38} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2023-10-27T13:40:26.831+1300[0m] {[34mexample_local_kubernetes_executor.py:[0m39} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 37, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2023-10-27T13:40:26.832+1300[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2023-10-27T13:40:26.856+1300[0m] {[34mdagbag.py:[0m505} ERROR[0m - Exception bagging dag: example_bash_operator[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 496, in _bag_dag
    raise AirflowDagDuplicatedIdException(
airflow.exceptions.AirflowDagDuplicatedIdException: Ignoring DAG example_bash_operator from /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py - also found in /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py
[[34m2023-10-27T13:40:26.857+1300[0m] {[34mdagbag.py:[0m443} ERROR[0m - Failed to bag_dag: /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 439, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 458, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 496, in _bag_dag
    raise AirflowDagDuplicatedIdException(
airflow.exceptions.AirflowDagDuplicatedIdException: Ignoring DAG example_bash_operator from /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py - also found in /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py
[[34m2023-10-27T13:40:26.858+1300[0m] {[34mdagbag.py:[0m505} ERROR[0m - Exception bagging dag: example_bash_operator[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 496, in _bag_dag
    raise AirflowDagDuplicatedIdException(
airflow.exceptions.AirflowDagDuplicatedIdException: Ignoring DAG example_bash_operator from /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py - also found in /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py
[[34m2023-10-27T13:40:26.858+1300[0m] {[34mdagbag.py:[0m443} ERROR[0m - Failed to bag_dag: /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 439, in _process_modules
    self.bag_dag(dag=dag, root_dag=dag)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 458, in bag_dag
    self._bag_dag(dag=dag, root_dag=root_dag, recursive=True)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 496, in _bag_dag
    raise AirflowDagDuplicatedIdException(
airflow.exceptions.AirflowDagDuplicatedIdException: Ignoring DAG example_bash_operator from /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_bash_operator.py - also found in /home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py
[[34m2023-10-27T13:40:27.344+1300[0m] {[34mdagbag.py:[0m346} ERROR[0m - Failed to import: /home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_subdag_operator.py[0m
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: no such column: slot_pool.include_deferred

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dagbag.py", line 342, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/example_dags/example_subdag_operator.py", line 43, in <module>
    section_1 = SubDagOperator(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/operators/subdag.py", line 90, in __init__
    self._validate_pool(session)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/operators/subdag.py", line 115, in _validate_pool
    pool = session.query(Pool).filter(Pool.slots == 1).filter(Pool.pool == self.pool).first()
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/query.py", line 2824, in first
    return self.limit(1)._iter().first()
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/query.py", line 2916, in _iter
    result = self.session.execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such column: slot_pool.include_deferred
[SQL: SELECT slot_pool.id AS slot_pool_id, slot_pool.pool AS slot_pool_pool, slot_pool.slots AS slot_pool_slots, slot_pool.description AS slot_pool_description, slot_pool.include_deferred AS slot_pool_include_deferred 
FROM slot_pool 
WHERE slot_pool.slots = ? AND slot_pool.pool = ?
 LIMIT ? OFFSET ?]
[parameters: (1, 'default_pool', 1, 0)]
(Background on this error at: https://sqlalche.me/e/14/e3q8)
Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlite3.OperationalError: no such column: dag_run.updated_at

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/bin/airflow", line 11, in <module>
    sys.exit(main())
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/__main__.py", line 59, in main
    args.func(args)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/cli.py", line 113, in wrapper
    return f(*args, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 411, in task_run
    ti, _ = _get_ti(task, args.map_index, exec_date_or_run_id=args.execution_date_or_run_id, pool=args.pool)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/session.py", line 77, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 175, in _get_ti
    dag_run, dr_created = _get_dag_run(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/cli/commands/task_command.py", line 111, in _get_dag_run
    dag_run = dag.get_dagrun(run_id=exec_date_or_run_id, session=session)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/utils/session.py", line 74, in wrapper
    return func(*args, **kwargs)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/airflow/models/dag.py", line 1491, in get_dagrun
    return session.scalar(query)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/orm/session.py", line 1717, in execute
    result = conn._execute_20(statement, params or {}, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1710, in _execute_20
    return meth(self, args_10style, kwargs_10style, execution_options)
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/sql/elements.py", line 334, in _execute_on_connection
    return connection._execute_clauseelement(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1577, in _execute_clauseelement
    ret = self._execute_context(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/zhangs/miniconda3/envs/ptd_esr_env/lib/python3.10/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such column: dag_run.updated_at
[SQL: SELECT dag_run.state, dag_run.id, dag_run.dag_id, dag_run.queued_at, dag_run.execution_date, dag_run.start_date, dag_run.end_date, dag_run.run_id, dag_run.creating_job_id, dag_run.external_trigger, dag_run.run_type, dag_run.conf, dag_run.data_interval_start, dag_run.data_interval_end, dag_run.last_scheduling_decision, dag_run.dag_hash, dag_run.log_template_id, dag_run.updated_at 
FROM dag_run 
WHERE dag_run.dag_id = ? AND dag_run.run_id = ?]
[parameters: ('example_bash_operator', 'manual__2023-10-27T00:39:54.194185+00:00')]
(Background on this error at: https://sqlalche.me/e/14/e3q8)
[[34m2023-10-27 13:40:28,306[0m] {[34msequential_executor.py:[0m68} ERROR[0m - Failed to execute task Command '['airflow', 'tasks', 'run', 'example_bash_operator', 'this_will_skip', 'manual__2023-10-27T00:39:54.194185+00:00', '--local', '--subdir', '/home/zhangs/miniconda3/envs/airflow/lib/python3.9/site-packages/airflow/example_dags/example_bash_operator.py']' returned non-zero exit status 1..[0m
[[34m2023-10-27 13:40:28,309[0m] {[34mscheduler_job.py:[0m588} INFO[0m - Executor reports execution of example_bash_operator.runme_0 run_id=scheduled__2023-10-26T00:00:00+00:00 exited with status failed for try_number 1[0m
[[34m2023-10-27 13:40:28,311[0m] {[34mscheduler_job.py:[0m588} INFO[0m - Executor reports execution of example_bash_operator.runme_1 run_id=scheduled__2023-10-26T00:00:00+00:00 exited with status failed for try_number 1[0m
[[34m2023-10-27 13:40:28,311[0m] {[34mscheduler_job.py:[0m588} INFO[0m - Executor reports execution of example_bash_operator.runme_2 run_id=scheduled__2023-10-26T00:00:00+00:00 exited with status failed for try_number 1[0m
[[34m2023-10-27 13:40:28,311[0m] {[34mscheduler_job.py:[0m588} INFO[0m - Executor reports execution of example_bash_operator.runme_0 run_id=manual__2023-10-27T00:39:54.194185+00:00 exited with status failed for try_number 1[0m
[[34m2023-10-27 13:40:28,312[0m] {[34mscheduler_job.py:[0m588} INFO[0m - Executor reports execution of example_bash_operator.runme_1 run_id=manual__2023-10-27T00:39:54.194185+00:00 exited with status failed for try_number 1[0m
[[34m2023-10-27 13:40:28,312[0m] {[34mscheduler_job.py:[0m588} INFO[0m - Executor reports execution of example_bash_operator.runme_2 run_id=manual__2023-10-27T00:39:54.194185+00:00 exited with status failed for try_number 1[0m
[[34m2023-10-27 13:40:28,313[0m] {[34mscheduler_job.py:[0m588} INFO[0m - Executor reports execution of example_bash_operator.also_run_this run_id=scheduled__2023-10-26T00:00:00+00:00 exited with status failed for try_number 1[0m
[[34m2023-10-27 13:40:28,313[0m] {[34mscheduler_job.py:[0m588} INFO[0m - Executor reports execution of example_bash_operator.this_will_skip run_id=scheduled__2023-10-26T00:00:00+00:00 exited with status failed for try_number 1[0m
[[34m2023-10-27 13:40:28,313[0m] {[34mscheduler_job.py:[0m588} INFO[0m - Executor reports execution of example_bash_operator.also_run_this run_id=manual__2023-10-27T00:39:54.194185+00:00 exited with status failed for try_number 1[0m
[[34m2023-10-27 13:40:28,313[0m] {[34mscheduler_job.py:[0m588} INFO[0m - Executor reports execution of example_bash_operator.this_will_skip run_id=manual__2023-10-27T00:39:54.194185+00:00 exited with status failed for try_number 1[0m
[[34m2023-10-27 13:40:28,349[0m] {[34mscheduler_job.py:[0m631} INFO[0m - TaskInstance Finished: dag_id=example_bash_operator, task_id=also_run_this, run_id=manual__2023-10-27T00:39:54.194185+00:00, map_index=-1, run_start_date=None, run_end_date=None, run_duration=None, state=queued, executor_state=failed, try_number=1, max_tries=0, job_id=None, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2023-10-27 00:39:55.740304+00:00, queued_by_job_id=11, pid=None[0m
[[34m2023-10-27 13:40:28,349[0m] {[34mscheduler_job.py:[0m673} ERROR[0m - Executor reports task instance <TaskInstance: example_bash_operator.also_run_this manual__2023-10-27T00:39:54.194185+00:00 [queued]> finished (failed) although the task says its queued. (Info: None) Was the task killed externally?[0m
[[34m2023-10-27 13:40:28,356[0m] {[34mtaskinstance.py:[0m1853} ERROR[0m - Executor reports task instance <TaskInstance: example_bash_operator.also_run_this manual__2023-10-27T00:39:54.194185+00:00 [queued]> finished (failed) although the task says its queued. (Info: None) Was the task killed externally?[0m
[[34m2023-10-27 13:40:28,386[0m] {[34mtaskinstance.py:[0m1401} INFO[0m - Marking task as FAILED. dag_id=example_bash_operator, task_id=also_run_this, execution_date=20231027T003954, start_date=, end_date=20231027T004028[0m
[[34m2023-10-27 13:40:28,412[0m] {[34mscheduler_job.py:[0m631} INFO[0m - TaskInstance Finished: dag_id=example_bash_operator, task_id=runme_0, run_id=manual__2023-10-27T00:39:54.194185+00:00, map_index=-1, run_start_date=None, run_end_date=None, run_duration=None, state=queued, executor_state=failed, try_number=1, max_tries=0, job_id=None, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2023-10-27 00:39:55.740304+00:00, queued_by_job_id=11, pid=None[0m
[[34m2023-10-27 13:40:28,412[0m] {[34mscheduler_job.py:[0m673} ERROR[0m - Executor reports task instance <TaskInstance: example_bash_operator.runme_0 manual__2023-10-27T00:39:54.194185+00:00 [queued]> finished (failed) although the task says its queued. (Info: None) Was the task killed externally?[0m
[[34m2023-10-27 13:40:28,427[0m] {[34mtaskinstance.py:[0m1853} ERROR[0m - Executor reports task instance <TaskInstance: example_bash_operator.runme_0 manual__2023-10-27T00:39:54.194185+00:00 [queued]> finished (failed) although the task says its queued. (Info: None) Was the task killed externally?[0m
[[34m2023-10-27 13:40:28,456[0m] {[34mtaskinstance.py:[0m1401} INFO[0m - Marking task as FAILED. dag_id=example_bash_operator, task_id=runme_0, execution_date=20231027T003954, start_date=, end_date=20231027T004028[0m
[[34m2023-10-27 13:40:28,484[0m] {[34mscheduler_job.py:[0m631} INFO[0m - TaskInstance Finished: dag_id=example_bash_operator, task_id=runme_1, run_id=manual__2023-10-27T00:39:54.194185+00:00, map_index=-1, run_start_date=None, run_end_date=None, run_duration=None, state=queued, executor_state=failed, try_number=1, max_tries=0, job_id=None, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2023-10-27 00:39:55.740304+00:00, queued_by_job_id=11, pid=None[0m
[[34m2023-10-27 13:40:28,485[0m] {[34mscheduler_job.py:[0m673} ERROR[0m - Executor reports task instance <TaskInstance: example_bash_operator.runme_1 manual__2023-10-27T00:39:54.194185+00:00 [queued]> finished (failed) although the task says its queued. (Info: None) Was the task killed externally?[0m
[[34m2023-10-27 13:40:28,502[0m] {[34mtaskinstance.py:[0m1853} ERROR[0m - Executor reports task instance <TaskInstance: example_bash_operator.runme_1 manual__2023-10-27T00:39:54.194185+00:00 [queued]> finished (failed) although the task says its queued. (Info: None) Was the task killed externally?[0m
[[34m2023-10-27 13:40:28,535[0m] {[34mtaskinstance.py:[0m1401} INFO[0m - Marking task as FAILED. dag_id=example_bash_operator, task_id=runme_1, execution_date=20231027T003954, start_date=, end_date=20231027T004028[0m
[[34m2023-10-27 13:40:28,563[0m] {[34mscheduler_job.py:[0m631} INFO[0m - TaskInstance Finished: dag_id=example_bash_operator, task_id=runme_2, run_id=manual__2023-10-27T00:39:54.194185+00:00, map_index=-1, run_start_date=None, run_end_date=None, run_duration=None, state=queued, executor_state=failed, try_number=1, max_tries=0, job_id=None, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2023-10-27 00:39:55.740304+00:00, queued_by_job_id=11, pid=None[0m
[[34m2023-10-27 13:40:28,564[0m] {[34mscheduler_job.py:[0m673} ERROR[0m - Executor reports task instance <TaskInstance: example_bash_operator.runme_2 manual__2023-10-27T00:39:54.194185+00:00 [queued]> finished (failed) although the task says its queued. (Info: None) Was the task killed externally?[0m
[[34m2023-10-27 13:40:28,579[0m] {[34mtaskinstance.py:[0m1853} ERROR[0m - Executor reports task instance <TaskInstance: example_bash_operator.runme_2 manual__2023-10-27T00:39:54.194185+00:00 [queued]> finished (failed) although the task says its queued. (Info: None) Was the task killed externally?[0m
[[34m2023-10-27 13:40:28,609[0m] {[34mtaskinstance.py:[0m1401} INFO[0m - Marking task as FAILED. dag_id=example_bash_operator, task_id=runme_2, execution_date=20231027T003954, start_date=, end_date=20231027T004028[0m
[[34m2023-10-27 13:40:28,634[0m] {[34mscheduler_job.py:[0m631} INFO[0m - TaskInstance Finished: dag_id=example_bash_operator, task_id=this_will_skip, run_id=manual__2023-10-27T00:39:54.194185+00:00, map_index=-1, run_start_date=None, run_end_date=None, run_duration=None, state=queued, executor_state=failed, try_number=1, max_tries=0, job_id=None, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2023-10-27 00:39:55.740304+00:00, queued_by_job_id=11, pid=None[0m
[[34m2023-10-27 13:40:28,634[0m] {[34mscheduler_job.py:[0m673} ERROR[0m - Executor reports task instance <TaskInstance: example_bash_operator.this_will_skip manual__2023-10-27T00:39:54.194185+00:00 [queued]> finished (failed) although the task says its queued. (Info: None) Was the task killed externally?[0m
[[34m2023-10-27 13:40:28,650[0m] {[34mtaskinstance.py:[0m1853} ERROR[0m - Executor reports task instance <TaskInstance: example_bash_operator.this_will_skip manual__2023-10-27T00:39:54.194185+00:00 [queued]> finished (failed) although the task says its queued. (Info: None) Was the task killed externally?[0m
[[34m2023-10-27 13:40:28,679[0m] {[34mtaskinstance.py:[0m1401} INFO[0m - Marking task as FAILED. dag_id=example_bash_operator, task_id=this_will_skip, execution_date=20231027T003954, start_date=, end_date=20231027T004028[0m
[[34m2023-10-27 13:40:28,705[0m] {[34mscheduler_job.py:[0m631} INFO[0m - TaskInstance Finished: dag_id=example_bash_operator, task_id=also_run_this, run_id=scheduled__2023-10-26T00:00:00+00:00, map_index=-1, run_start_date=None, run_end_date=None, run_duration=None, state=queued, executor_state=failed, try_number=1, max_tries=0, job_id=None, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2023-10-27 00:39:55.740304+00:00, queued_by_job_id=11, pid=None[0m
[[34m2023-10-27 13:40:28,706[0m] {[34mscheduler_job.py:[0m673} ERROR[0m - Executor reports task instance <TaskInstance: example_bash_operator.also_run_this scheduled__2023-10-26T00:00:00+00:00 [queued]> finished (failed) although the task says its queued. (Info: None) Was the task killed externally?[0m
[[34m2023-10-27 13:40:28,721[0m] {[34mtaskinstance.py:[0m1853} ERROR[0m - Executor reports task instance <TaskInstance: example_bash_operator.also_run_this scheduled__2023-10-26T00:00:00+00:00 [queued]> finished (failed) although the task says its queued. (Info: None) Was the task killed externally?[0m
[[34m2023-10-27 13:40:28,755[0m] {[34mtaskinstance.py:[0m1401} INFO[0m - Marking task as FAILED. dag_id=example_bash_operator, task_id=also_run_this, execution_date=20231026T000000, start_date=, end_date=20231027T004028[0m
[[34m2023-10-27 13:40:28,777[0m] {[34mscheduler_job.py:[0m631} INFO[0m - TaskInstance Finished: dag_id=example_bash_operator, task_id=runme_0, run_id=scheduled__2023-10-26T00:00:00+00:00, map_index=-1, run_start_date=None, run_end_date=None, run_duration=None, state=queued, executor_state=failed, try_number=1, max_tries=0, job_id=None, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2023-10-27 00:39:55.740304+00:00, queued_by_job_id=11, pid=None[0m
[[34m2023-10-27 13:40:28,778[0m] {[34mscheduler_job.py:[0m673} ERROR[0m - Executor reports task instance <TaskInstance: example_bash_operator.runme_0 scheduled__2023-10-26T00:00:00+00:00 [queued]> finished (failed) although the task says its queued. (Info: None) Was the task killed externally?[0m
[[34m2023-10-27 13:40:28,792[0m] {[34mtaskinstance.py:[0m1853} ERROR[0m - Executor reports task instance <TaskInstance: example_bash_operator.runme_0 scheduled__2023-10-26T00:00:00+00:00 [queued]> finished (failed) although the task says its queued. (Info: None) Was the task killed externally?[0m
[[34m2023-10-27 13:40:28,823[0m] {[34mtaskinstance.py:[0m1401} INFO[0m - Marking task as FAILED. dag_id=example_bash_operator, task_id=runme_0, execution_date=20231026T000000, start_date=, end_date=20231027T004028[0m
[[34m2023-10-27 13:40:28,847[0m] {[34mscheduler_job.py:[0m631} INFO[0m - TaskInstance Finished: dag_id=example_bash_operator, task_id=runme_1, run_id=scheduled__2023-10-26T00:00:00+00:00, map_index=-1, run_start_date=None, run_end_date=None, run_duration=None, state=queued, executor_state=failed, try_number=1, max_tries=0, job_id=None, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2023-10-27 00:39:55.740304+00:00, queued_by_job_id=11, pid=None[0m
[[34m2023-10-27 13:40:28,847[0m] {[34mscheduler_job.py:[0m673} ERROR[0m - Executor reports task instance <TaskInstance: example_bash_operator.runme_1 scheduled__2023-10-26T00:00:00+00:00 [queued]> finished (failed) although the task says its queued. (Info: None) Was the task killed externally?[0m
[[34m2023-10-27 13:40:28,862[0m] {[34mtaskinstance.py:[0m1853} ERROR[0m - Executor reports task instance <TaskInstance: example_bash_operator.runme_1 scheduled__2023-10-26T00:00:00+00:00 [queued]> finished (failed) although the task says its queued. (Info: None) Was the task killed externally?[0m
[[34m2023-10-27 13:40:28,892[0m] {[34mtaskinstance.py:[0m1401} INFO[0m - Marking task as FAILED. dag_id=example_bash_operator, task_id=runme_1, execution_date=20231026T000000, start_date=, end_date=20231027T004028[0m
[[34m2023-10-27 13:40:28,916[0m] {[34mscheduler_job.py:[0m631} INFO[0m - TaskInstance Finished: dag_id=example_bash_operator, task_id=runme_2, run_id=scheduled__2023-10-26T00:00:00+00:00, map_index=-1, run_start_date=None, run_end_date=None, run_duration=None, state=queued, executor_state=failed, try_number=1, max_tries=0, job_id=None, pool=default_pool, queue=default, priority_weight=3, operator=BashOperator, queued_dttm=2023-10-27 00:39:55.740304+00:00, queued_by_job_id=11, pid=None[0m
[[34m2023-10-27 13:40:28,916[0m] {[34mscheduler_job.py:[0m673} ERROR[0m - Executor reports task instance <TaskInstance: example_bash_operator.runme_2 scheduled__2023-10-26T00:00:00+00:00 [queued]> finished (failed) although the task says its queued. (Info: None) Was the task killed externally?[0m
[[34m2023-10-27 13:40:28,931[0m] {[34mtaskinstance.py:[0m1853} ERROR[0m - Executor reports task instance <TaskInstance: example_bash_operator.runme_2 scheduled__2023-10-26T00:00:00+00:00 [queued]> finished (failed) although the task says its queued. (Info: None) Was the task killed externally?[0m
[[34m2023-10-27 13:40:28,961[0m] {[34mtaskinstance.py:[0m1401} INFO[0m - Marking task as FAILED. dag_id=example_bash_operator, task_id=runme_2, execution_date=20231026T000000, start_date=, end_date=20231027T004028[0m
[[34m2023-10-27 13:40:28,985[0m] {[34mscheduler_job.py:[0m631} INFO[0m - TaskInstance Finished: dag_id=example_bash_operator, task_id=this_will_skip, run_id=scheduled__2023-10-26T00:00:00+00:00, map_index=-1, run_start_date=None, run_end_date=None, run_duration=None, state=queued, executor_state=failed, try_number=1, max_tries=0, job_id=None, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2023-10-27 00:39:55.740304+00:00, queued_by_job_id=11, pid=None[0m
[[34m2023-10-27 13:40:28,985[0m] {[34mscheduler_job.py:[0m673} ERROR[0m - Executor reports task instance <TaskInstance: example_bash_operator.this_will_skip scheduled__2023-10-26T00:00:00+00:00 [queued]> finished (failed) although the task says its queued. (Info: None) Was the task killed externally?[0m
[[34m2023-10-27 13:40:29,000[0m] {[34mtaskinstance.py:[0m1853} ERROR[0m - Executor reports task instance <TaskInstance: example_bash_operator.this_will_skip scheduled__2023-10-26T00:00:00+00:00 [queued]> finished (failed) although the task says its queued. (Info: None) Was the task killed externally?[0m
[[34m2023-10-27 13:40:29,029[0m] {[34mtaskinstance.py:[0m1401} INFO[0m - Marking task as FAILED. dag_id=example_bash_operator, task_id=this_will_skip, execution_date=20231026T000000, start_date=, end_date=20231027T004029[0m
[[34m2023-10-27 13:40:31,334[0m] {[34mdagrun.py:[0m578} ERROR[0m - Marking run <DagRun example_bash_operator @ 2023-10-26 00:00:00+00:00: scheduled__2023-10-26T00:00:00+00:00, state:running, queued_at: 2023-10-27 00:39:55.532900+00:00. externally triggered: False> failed[0m
[[34m2023-10-27 13:40:31,335[0m] {[34mdagrun.py:[0m644} INFO[0m - DagRun Finished: dag_id=example_bash_operator, execution_date=2023-10-26 00:00:00+00:00, run_id=scheduled__2023-10-26T00:00:00+00:00, run_start_date=2023-10-27 00:39:55.593657+00:00, run_end_date=2023-10-27 00:40:31.335284+00:00, run_duration=35.741627, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2023-10-26 00:00:00+00:00, data_interval_end=2023-10-27 00:00:00+00:00, dag_hash=f90970cae75b39d8aec3778303656d13[0m
[[34m2023-10-27 13:40:31,347[0m] {[34mdag.py:[0m3336} INFO[0m - Setting next_dagrun for example_bash_operator to 2023-10-27T00:00:00+00:00, run_after=2023-10-28T00:00:00+00:00[0m
[[34m2023-10-27 13:40:31,351[0m] {[34mdagrun.py:[0m578} ERROR[0m - Marking run <DagRun example_bash_operator @ 2023-10-27 00:39:54.194185+00:00: manual__2023-10-27T00:39:54.194185+00:00, state:running, queued_at: 2023-10-27 00:39:54.307519+00:00. externally triggered: True> failed[0m
[[34m2023-10-27 13:40:31,352[0m] {[34mdagrun.py:[0m644} INFO[0m - DagRun Finished: dag_id=example_bash_operator, execution_date=2023-10-27 00:39:54.194185+00:00, run_id=manual__2023-10-27T00:39:54.194185+00:00, run_start_date=2023-10-27 00:39:55.594120+00:00, run_end_date=2023-10-27 00:40:31.352052+00:00, run_duration=35.757932, state=failed, external_trigger=True, run_type=manual, data_interval_start=2023-10-26 00:00:00+00:00, data_interval_end=2023-10-27 00:00:00+00:00, dag_hash=f90970cae75b39d8aec3778303656d13[0m
[[34m2023-10-27 13:40:31,356[0m] {[34mdag.py:[0m3336} INFO[0m - Setting next_dagrun for example_bash_operator to 2023-10-27T00:00:00+00:00, run_after=2023-10-28T00:00:00+00:00[0m
[[34m2023-10-27 13:41:15,691[0m] {[34mscheduler_job.py:[0m1380} INFO[0m - Resetting orphaned tasks for active dag runs[0m
make: *** [scheduler] Killed
